<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.31">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Yekta Amirkhalili">
<meta name="dcterms.date" content="2025-06-22">

<title>Topic Modeling – Yekta’s Dissertation</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-8ef56b68f8fa1e9d2ba328e99e439f80.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-e1a5c8363afafaef2c763b6775fbf3ca.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-02e7b63b13b23c0d612b4df9d70fa878.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-e1c82c21f31fdb0f854370cce998e929.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-02e7b63b13b23c0d612b4df9d70fa878.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar docked nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Yekta’s Dissertation</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="./index.html" aria-current="page"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./study1.html">Projects</a></li><li class="breadcrumb-item"><a href="./study1.html">Project 1. SLR</a></li><li class="breadcrumb-item"><a href="./study1_tm.html">Topic Modeling</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
        <div class="sidebar-tools-collapse">
    <a href="./github.com/YektaDissertation" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
</div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Home</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./basics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Basics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./techAdopt.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Technology Adoption</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mobileBanking.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Mobile Banking</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Projects</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./study1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Project 1. SLR</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./study1_tm.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Topic Modeling</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./study1_theme.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Algorithmic Approach to Finding Themes</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./study1_DA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Data Analysis</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./study2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Project 2. Mental Health</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./study2_DA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Effect Of Mental Health on Mobile Banking</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./study3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Project 3. Digital Divide</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./study3_DA.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">study3_DA.html</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar"><div class="quarto-margin-header"><div class="margin-header-item">
<p><img src="./images/uw-logo.png" class="img-fluid"></p>
</div></div>
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#part-0.-jupyter-notebook" id="toc-part-0.-jupyter-notebook" class="nav-link active" data-scroll-target="#part-0.-jupyter-notebook">Part 0. Jupyter Notebook</a></li>
  <li><a href="#part-1." id="toc-part-1." class="nav-link" data-scroll-target="#part-1.">Part 1.</a>
  <ul class="collapse">
  <li><a href="#cleaning-and-pre-processing-data" id="toc-cleaning-and-pre-processing-data" class="nav-link" data-scroll-target="#cleaning-and-pre-processing-data">CLEANING AND PRE-PROCESSING DATA</a></li>
  <li><a href="#topic-modeling-using-keywords" id="toc-topic-modeling-using-keywords" class="nav-link" data-scroll-target="#topic-modeling-using-keywords">Topic Modeling using Keywords</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./study1.html">Projects</a></li><li class="breadcrumb-item"><a href="./study1.html">Project 1. SLR</a></li><li class="breadcrumb-item"><a href="./study1_tm.html">Topic Modeling</a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Topic Modeling</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Yekta Amirkhalili </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 22, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<!-- CSS CHANGES -->
<style>
.quarto-title h1.title {
  font-size: 1.5rem; 
}

h2{
    font-size: 1.2rem;
    background-color:rgba(128, 170, 156, 0.48);
}

.future-idea-box {
  border: 2px solid var(--quarto-hl-header-color, #86bdab); /* Uses Quarto header color variable or fallback */
  border-radius: 8px;
  padding: 1em;
  margin: 1em 0;
  background: #f9f9fc;
}
.future-idea-title {
  font-weight: bold;
  color: var(--quarto-hl-header-color,rgb(111, 172, 152));
  margin-bottom: 0.5em;
  font-size: 1.1em;
}

</style>
<!-- CSS CHANGES -->
<section id="part-0.-jupyter-notebook" class="level2">
<h2 class="anchored" data-anchor-id="part-0.-jupyter-notebook">Part 0. Jupyter Notebook</h2>
<p>If you want to run the entire code, use the Jupyter notebook on my github page.</p>
</section>
<section id="part-1." class="level2">
<h2 class="anchored" data-anchor-id="part-1.">Part 1.</h2>
<p>First things first, we need a bunch of libraries. Since I am not familiar with <a href="https://www.docker.com/">Docker</a>, I couldn’t resolve the package dependencies. This took so much time for me and I finally managed to fix it with this specific configuration.</p>
<div id="93065a5b" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>__requires__<span class="op">=</span> <span class="st">'scipy==1.12.0'</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(scipy.__version__)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The imports look scary, but a lot of them I won’t even use, just added them because I wanted to try things:</p>
<div id="2ce3c91a" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># general python imports </span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> string</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np </span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> textract</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co"># NLT imports </span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk <span class="im">import</span> pos_tag</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="co">#from nltk.tokenize import regexp_tokenize</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> word_tokenize</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> sent_tokenize</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> stopwords</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.stem <span class="im">import</span> WordNetLemmatizer</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> wordnet</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.stem.porter <span class="im">import</span> PorterStemmer</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.util <span class="im">import</span> ngrams</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> RegexpTokenizer</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a><span class="co"># SKLEARN </span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> metrics</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> neighbors</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> r2_score</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.ensemble import RandomForestClassifier</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.metrics import classification_report</span></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.naive_bayes import MultinomialNB</span></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.neighbors import NearestNeighbors</span></span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.preprocessing import LabelEncoder</span></span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.metrics import classification_report,confusion_matrix,accuracy_score</span></span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.naive_bayes import (</span></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a><span class="co">#     BernoulliNB,</span></span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a><span class="co">#     ComplementNB,</span></span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a><span class="co">#     MultinomialNB,</span></span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a><span class="co"># )</span></span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.neighbors import KNeighborsClassifier</span></span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.tree import DecisionTreeClassifier</span></span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.ensemble import RandomForestClassifier</span></span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.linear_model import LogisticRegression</span></span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.neural_network import MLPClassifier</span></span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis</span></span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.decomposition import LatentDirichletAllocation</span></span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a><span class="co"># GENSIM imports </span></span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gensim</span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models <span class="im">import</span> Phrases</span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models.phrases <span class="im">import</span> Phraser</span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.corpora.dictionary <span class="im">import</span> Dictionary</span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.corpora <span class="im">import</span> MmCorpus</span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models.tfidfmodel <span class="im">import</span> TfidfModel</span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models <span class="im">import</span> CoherenceModel</span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models <span class="im">import</span> KeyedVectors</span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-64"><a href="#cb2-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-65"><a href="#cb2-65" aria-hidden="true" tabindex="-1"></a><span class="co"># PyLDAvis imports </span></span>
<span id="cb2-66"><a href="#cb2-66" aria-hidden="true" tabindex="-1"></a><span class="co"># import pyLDAvis</span></span>
<span id="cb2-67"><a href="#cb2-67" aria-hidden="true" tabindex="-1"></a><span class="co"># import pyLDAvis.gensim_models as gensimvis</span></span>
<span id="cb2-68"><a href="#cb2-68" aria-hidden="true" tabindex="-1"></a><span class="co"># import pyLDAvis.gensim</span></span>
<span id="cb2-69"><a href="#cb2-69" aria-hidden="true" tabindex="-1"></a><span class="co"># import pyLDAvis.gensim_models</span></span>
<span id="cb2-70"><a href="#cb2-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-71"><a href="#cb2-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-72"><a href="#cb2-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-73"><a href="#cb2-73" aria-hidden="true" tabindex="-1"></a><span class="co"># MISC imports </span></span>
<span id="cb2-74"><a href="#cb2-74" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb2-75"><a href="#cb2-75" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> defaultdict</span>
<span id="cb2-76"><a href="#cb2-76" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> string <span class="im">import</span> punctuation</span>
<span id="cb2-77"><a href="#cb2-77" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pprint <span class="im">import</span> pprint</span>
<span id="cb2-78"><a href="#cb2-78" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> triu</span>
<span id="cb2-79"><a href="#cb2-79" aria-hidden="true" tabindex="-1"></a><span class="co">#from scipy.linalg.special_matrices import triu</span></span>
<span id="cb2-80"><a href="#cb2-80" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.sparse <span class="im">import</span> csr_matrix</span>
<span id="cb2-81"><a href="#cb2-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-82"><a href="#cb2-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-83"><a href="#cb2-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-84"><a href="#cb2-84" aria-hidden="true" tabindex="-1"></a><span class="co"># TRANSFORMERS </span></span>
<span id="cb2-85"><a href="#cb2-85" aria-hidden="true" tabindex="-1"></a><span class="co">#import torch</span></span>
<span id="cb2-86"><a href="#cb2-86" aria-hidden="true" tabindex="-1"></a><span class="co">#import tensorflow as tf</span></span>
<span id="cb2-87"><a href="#cb2-87" aria-hidden="true" tabindex="-1"></a><span class="co">#from transformers import BertTokenizer, BertModel</span></span>
<span id="cb2-88"><a href="#cb2-88" aria-hidden="true" tabindex="-1"></a><span class="co">#from tensorflow.keras.models import Sequential</span></span>
<span id="cb2-89"><a href="#cb2-89" aria-hidden="true" tabindex="-1"></a><span class="co">#from tensorflow.keras.preprocessing.text import Tokenizer</span></span>
<span id="cb2-90"><a href="#cb2-90" aria-hidden="true" tabindex="-1"></a><span class="co">#from tensorflow.keras.preprocessing.sequence import pad_sequences</span></span>
<span id="cb2-91"><a href="#cb2-91" aria-hidden="true" tabindex="-1"></a><span class="co">#from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D</span></span>
<span id="cb2-92"><a href="#cb2-92" aria-hidden="true" tabindex="-1"></a><span class="co">#from tensorflow.keras.layers import LeakyReLU</span></span>
<span id="cb2-93"><a href="#cb2-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-94"><a href="#cb2-94" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> fitz  <span class="co"># PyMuPDF</span></span>
<span id="cb2-95"><a href="#cb2-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-96"><a href="#cb2-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-97"><a href="#cb2-97" aria-hidden="true" tabindex="-1"></a><span class="co"># MATPLOT </span></span>
<span id="cb2-98"><a href="#cb2-98" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-99"><a href="#cb2-99" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb2-100"><a href="#cb2-100" aria-hidden="true" tabindex="-1"></a><span class="co">#%matplotlib inline # do this if you're in jupyter, I still don't know why tho </span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="3d3114d1" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># only run once</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'stopwords'</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'punkt'</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'wordnet'</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'punkt_tab'</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co">#nltk.download('omw-1.4')  # Optional for better language support</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co">#nltk.download('averaged_perceptron_tagger')  # For POS tagging</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co">#nltk.download('averaged_perceptron_tagger_eng')</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="cleaning-and-pre-processing-data" class="level3">
<h3 class="anchored" data-anchor-id="cleaning-and-pre-processing-data">CLEANING AND PRE-PROCESSING DATA</h3>
<p>I downloaded the pdf of all the papers (143), reading them and extracting meta data based on the following:</p>
<div id="6430a68e" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np </span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>database <span class="op">=</span> np.array([</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">'id'</span>: <span class="st">'string'</span>, <span class="co"># unique identifier for the paper following convention P2_#number </span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">'title'</span>: <span class="st">'string'</span>, <span class="co"># title of the paper</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">'AffiliationCountry'</span>: <span class="st">'string'</span> , <span class="co">#name of country the study was conducted in,</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">'year'</span>: <span class="dv">2018</span><span class="op">-</span><span class="dv">2024</span>, <span class="co"># year of publication a value between 2018 and 2024</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">'journal'</span>: <span class="st">'string'</span>, <span class="co"># name of the journal the paper was published in</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">'citations'</span>: <span class="dv">0</span><span class="op">-</span><span class="dv">1000</span>, <span class="co"># number of citations the paper has received - not reported in the paper </span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">'year_since'</span>: <span class="dv">3</span>, <span class="co"># number of years since publication - not reported in the paper </span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">'cpy'</span>: <span class="dv">0</span>, <span class="co"># number of citations per year - not reported in the paper </span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">'keywords'</span>: [<span class="st">'TAM'</span>, <span class="st">'mbanking'</span>, <span class="st">'awareness'</span>], <span class="co"># list of keywords, broken into K1-K10</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>        <span class="st">'abstract'</span>: <span class="st">'string'</span>, <span class="co"># abstract of the paper </span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">'F'</span>: [<span class="st">'perceived usefulness'</span>], <span class="co"># factors significant in the study, broken into F1-F9 </span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>        <span class="st">'FN'</span>: [<span class="st">'another factor'</span>], <span class="co"># factors not significant in the study, broken into FNS1-FNS4 </span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">'limit'</span>: [<span class="st">'geographical context'</span>], <span class="co"># limitations of the study, broken into LIMIT1-LIMIT3 </span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>        <span class="st">'typeofResearch'</span>: <span class="st">'string'</span>, <span class="co"># type of research conducted in the study </span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">'methods'</span>: [<span class="st">'regression analysis'</span>], <span class="co"># methods used in the study, broken into METHOD1-METHOD4</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">'theory'</span>: [<span class="st">'TAM'</span>] <span class="co"># theories used in the study, broken into THEORY1-THEORY4</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">'sampleSize'</span>: <span class="dv">100</span>, <span class="co"># sample size of the study </span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">'tech'</span>: <span class="st">'string'</span>, <span class="co"># main technology studied </span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>        <span class="st">'man_theme'</span>: <span class="st">'string'</span>, <span class="co"># Theme manually assigned by me </span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>        <span class="st">'algo_theme'</span>: <span class="st">'string'</span>, <span class="co"># Theme assigned by the algorithm </span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>        <span class="st">'decision_Theme'</span>: <span class="st">'string'</span>, <span class="co"># Final theme of the paper  </span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Score_Sig'</span>: <span class="fl">0.0</span>, <span class="co"># % of significance for factors </span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Score_NOT_Sig'</span>: <span class="fl">0.0</span>, <span class="co"># % of non-significance for factors</span></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="future-idea-box">
<div class="future-idea-title">
<p>Idea for future</p>
</div>
<p>🤖 Build an Agentic AI application that automates this process.</p>
</div>
<p>The following procedures are implemented for Data Cleaning:</p>
<ol type="1">
<li>Turn everything into lower case</li>
<li>Remove stopwords + additional stopwords such as “bank”, “banking”, “banks”, “mobile”, “mbank”, “mbanking”, “m-bank”, “online”, “digital”, “adoption”, “theory”, “app”, “application”</li>
<li>Remove punctuation</li>
<li>Lemming/Stemming</li>
</ol>
<p>Grabbing the names of the pdf files (you can also do this from the terminal, and have the results be written to a <code>.txt</code> file).</p>
<div id="9c84ec38" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>pdf_directory <span class="op">=</span> <span class="st">"./pdfs/"</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>all_files <span class="op">=</span> os.listdir(pdf_directory)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>pdf_files <span class="op">=</span> [<span class="bu">file</span> <span class="cf">for</span> <span class="bu">file</span> <span class="kw">in</span> all_files <span class="cf">if</span> <span class="bu">file</span>.endswith(<span class="st">'.pdf'</span>)]</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>output_file <span class="op">=</span> <span class="st">"pdf_file_names.txt"</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(output_file, <span class="st">"w"</span>) <span class="im">as</span> f:</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> pdf <span class="kw">in</span> pdf_files:</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        f.write(pdf <span class="op">+</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"PDF file names have been saved to </span><span class="sc">{</span>output_file<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then saving them in a python dictionary:</p>
<div id="c2ede2ad" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>name_of_pdfs <span class="op">=</span> {</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">'p2_101'</span>: <span class="st">"Okocha and Awele Adibi - 2020 - Mobile banking adoption by business executives in.pdf"</span>,</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ... </span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Extract text:</p>
<div id="2e0f9176" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co">#version one using PyMuPDF - there's also textract </span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> extract_text_from_pdf(filename):</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> <span class="st">""</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>        doc <span class="op">=</span> fitz.<span class="bu">open</span>(filename)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> page_num <span class="kw">in</span> <span class="bu">range</span>(doc.page_count):</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>            page <span class="op">=</span> doc.load_page(page_num)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>            text <span class="op">+=</span> page.get_text()</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Error reading </span><span class="sc">{</span>filename<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> text</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="1fdc374c" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>text_of_pdfs_v1 <span class="op">=</span> {}</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> paper_id, filename <span class="kw">in</span> name_of_pdfs.items():</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> extract_text_from_pdf(filename)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    text_of_pdfs_v1[paper_id] <span class="op">=</span> text</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Print the extracted text from the first PDF</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> paper_id, text <span class="kw">in</span> text_of_pdfs_v1.items():</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Text from </span><span class="sc">{</span>paper_id<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>name_of_pdfs[paper_id]<span class="sc">}</span><span class="ss">):"</span>)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(text[:<span class="dv">500</span>])  <span class="co"># Print the first 500 characters of the text</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">break</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<blockquote class="blockquote">
<p>Text from p2_101 (Okocha and Awele Adibi - 2020 - Mobile banking adoption by business executives in .pdf): Mobile banking adoption by business executives in Nigeria Foluke Olabisi Okocha1* and Vera Awele Adibi2 1Centre for Learning Resources, Landmark University, Nigeria 2Doctoral student, University of Ibadan, Nigeria *Corresponding author email: dada.foluke@lmu.edu.ng, folukedada@yahoo.com Challenges with the adoption of mobile banking technologies are best understood by studies on adoption. This however requires understanding the factors that inﬂuence its adoption in a given region. Technology Acc</p>
</blockquote>
<p>Clean text:</p>
<div id="ea745151" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>stop_words <span class="op">=</span> stopwords.words(<span class="st">'english'</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>stop_words.extend([<span class="st">"bank"</span>, <span class="st">"banking"</span>, <span class="st">"banks"</span>, </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>                   <span class="st">"mobile"</span>, <span class="st">"mbank"</span>, <span class="st">"mbanking"</span>, <span class="st">"m-bank"</span>, <span class="st">"m bank"</span>,</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>                   <span class="st">"adoption"</span>, <span class="st">"acceptance"</span>, <span class="st">"accept"</span>, <span class="st">"theory"</span>, <span class="st">"technology"</span>, </span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>                   <span class="st">"purpose"</span>, <span class="st">"result"</span>, <span class="st">"method"</span>, <span class="co">#from abstracts </span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>                   <span class="st">"journal"</span>, <span class="st">"volume"</span>, <span class="st">"pp"</span>, <span class="st">"no"</span>, <span class="co">#from journal information </span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>                   <span class="st">"theory"</span>, <span class="st">"app"</span>, <span class="st">"application"</span>, <span class="st">"usage"</span>, <span class="st">"model"</span>])</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>stemmer <span class="op">=</span> PorterStemmer()</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>lemmatizer <span class="op">=</span> WordNetLemmatizer()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This is just one of the cleaning functions:</p>
<div id="952041d4" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> preprocess_Dict(dct):</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> k, v <span class="kw">in</span> dct.items():</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(v, <span class="bu">list</span>):</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>            processed_list <span class="op">=</span> []</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> item <span class="kw">in</span> v:</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>                item <span class="op">=</span> item.lower()</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>                item <span class="op">=</span> re.sub(<span class="vs">r'http</span><span class="dv">\S</span><span class="op">+</span><span class="vs">www</span><span class="dv">\S</span><span class="op">+</span><span class="vs">@</span><span class="dv">\S</span><span class="op">+</span><span class="vs">'</span>, <span class="st">''</span>, item)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>                item <span class="op">=</span> re.sub(<span class="vs">r'</span><span class="kw">(</span><span class="fu">?&lt;</span><span class="vs">=</span><span class="dv">\w</span><span class="kw">)</span><span class="vs">-</span><span class="ex">(</span><span class="fu">?=</span><span class="dv">\w</span><span class="ex">)</span><span class="vs">'</span>, <span class="st">' '</span>, item)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>                item <span class="op">=</span> re.sub(<span class="vs">r'</span><span class="pp">[^a-z0-9</span><span class="dv">\s</span><span class="ch">\n</span><span class="pp">]</span><span class="vs">'</span>, <span class="st">''</span>, item)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>                item <span class="op">=</span> re.sub(<span class="vs">r'</span><span class="dv">\s</span><span class="op">+</span><span class="vs">'</span>, <span class="st">' '</span>, item).strip()</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>                item <span class="op">=</span> re.sub(<span class="vs">r'</span><span class="dv">\d</span><span class="op">+</span><span class="vs">'</span>, <span class="st">''</span>, item).strip()</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>                item <span class="op">=</span> <span class="st">" "</span>.join([word <span class="cf">for</span> word <span class="kw">in</span> item.split() <span class="cf">if</span> word <span class="kw">not</span> <span class="kw">in</span> stop_words])</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>                item <span class="op">=</span> <span class="st">" "</span>.join([stemmer.stem(word) <span class="cf">for</span> word <span class="kw">in</span> item.split()])</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>                processed_list.append(item)</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>            dct[k] <span class="op">=</span> processed_list</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>            v <span class="op">=</span> v.lower()</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>            v <span class="op">=</span> re.sub(<span class="vs">r'http</span><span class="dv">\S</span><span class="op">+</span><span class="vs">www</span><span class="dv">\S</span><span class="op">+</span><span class="vs">@</span><span class="dv">\S</span><span class="op">+</span><span class="vs">'</span>, <span class="st">''</span>, v)</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>            v <span class="op">=</span> re.sub(<span class="vs">r'</span><span class="kw">(</span><span class="fu">?&lt;</span><span class="vs">=</span><span class="dv">\w</span><span class="kw">)</span><span class="vs">-</span><span class="ex">(</span><span class="fu">?=</span><span class="dv">\w</span><span class="ex">)</span><span class="vs">'</span>, <span class="st">' '</span>, v)</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>            v <span class="op">=</span> re.sub(<span class="vs">r'</span><span class="pp">[^a-z0-9</span><span class="dv">\s</span><span class="ch">\n</span><span class="pp">]</span><span class="vs">'</span>, <span class="st">''</span>, v)</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>            v <span class="op">=</span> re.sub(<span class="vs">r'</span><span class="dv">\s</span><span class="op">+</span><span class="vs">'</span>, <span class="st">' '</span>, v).strip()</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>            v <span class="op">=</span> re.sub(<span class="vs">r'</span><span class="dv">\d</span><span class="op">+</span><span class="vs">'</span>, <span class="st">''</span>, v).strip()</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>            v <span class="op">=</span> <span class="st">" "</span>.join([word <span class="cf">for</span> word <span class="kw">in</span> v.split() <span class="cf">if</span> word <span class="kw">not</span> <span class="kw">in</span> stop_words])</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>            v <span class="op">=</span> <span class="st">" "</span>.join([stemmer.stem(word) <span class="cf">for</span> word <span class="kw">in</span> v.split()])</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>            dct[k] <span class="op">=</span> v</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> dct</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Sentence Tokenizer:</p>
<div id="98f30ed2" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tokenizeToSentences(doc):</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> k, v <span class="kw">in</span> doc.items():</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(v, <span class="bu">bytes</span>):</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>            v <span class="op">=</span> v.decode(<span class="st">'utf-8'</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>          </span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>        v <span class="op">=</span> v.lower()</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>        v <span class="op">=</span> v.replace(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>, <span class="st">' '</span>)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>        v <span class="op">=</span> re.sub(<span class="vs">r'http</span><span class="dv">\S</span><span class="op">+</span><span class="vs">www</span><span class="dv">\S</span><span class="op">+</span><span class="vs">@</span><span class="dv">\S</span><span class="op">+</span><span class="vs">'</span>, <span class="st">''</span>, v)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>        <span class="co">#v = " ".join([str(s) for s in v])</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>        v <span class="op">=</span> sent_tokenize(v)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>        doc[k] <span class="op">=</span> v</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> doc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="38102e52" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>text_of_pdfs_uncleaned_tokenizedSentences_v1 <span class="op">=</span> tokenizeToSentences(text_of_pdfs_v1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Build uni and bi-grams:</p>
<div id="24363737" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>text_of_pdfs_uncleaned_tokenize_words_v1 <span class="op">=</span> {}</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>text_of_pdfs_uncleaned_tokenize_bigrams_v1 <span class="op">=</span> {}</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k, v <span class="kw">in</span> text_of_pdfs_uncleaned_tokenizedSentences_v1.items():</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">#v is a list of sentences </span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    text_of_pdfs_uncleaned_tokenize_words_v1[k] <span class="op">=</span> [word_tokenize(s) <span class="cf">for</span> s <span class="kw">in</span> v] <span class="co">#list of lists </span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    text_of_pdfs_uncleaned_tokenize_bigrams_v1[k] <span class="op">=</span> [<span class="bu">list</span>(ngrams(sentence, <span class="dv">2</span>)) <span class="cf">for</span> sentence <span class="kw">in</span> text_of_pdfs_uncleaned_tokenize_words_v1[k]] </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Clean:</p>
<div id="b7ce715d" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>text_of_pdfs_cleaned_tokenize_words_v1 <span class="op">=</span> {}</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k, v <span class="kw">in</span> text_of_pdfs_uncleaned_tokenize_words_v1.items():</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># v is a list of lists - where each outer list is a sentence, and the inner list is the words in that sentence. </span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    text_of_pdfs_cleaned_tokenize_words_v1[k] <span class="op">=</span> preprocess_listOfLists(v)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>text_of_pdfs_cleaned_tokenize_bigrams_v1 <span class="op">=</span> {}</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k, v <span class="kw">in</span> text_of_pdfs_cleaned_tokenize_words_v1.items():</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>    text_of_pdfs_cleaned_tokenize_bigrams_v1[k] <span class="op">=</span> [<span class="bu">list</span>(ngrams(sentence, <span class="dv">2</span>)) <span class="cf">for</span> sentence <span class="kw">in</span> v]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="9b7e791b" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>text_of_pdfs_cleaned_tokenize_words_v1[<span class="st">'p2_01'</span>][<span class="dv">0</span>][:<span class="dv">3</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<blockquote class="blockquote">
<p>[‘doi’, ‘jgim’, ‘global’]</p>
</blockquote>
<div id="89778f07" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>text_of_pdfs_cleaned_tokenize_bigrams_v1[<span class="st">'p2_01'</span>][<span class="dv">0</span>][:<span class="dv">3</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<blockquote class="blockquote">
<p>[(‘doi’, ‘jgim’), (‘jgim’, ‘global’), (‘global’, ‘inform’)]</p>
</blockquote>
<p>Stich the bi-grams together:</p>
<div id="9be54912" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>text_of_pdfs_cleaned_tokenize_bigrams_combined_v1 <span class="op">=</span> {}</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k, v <span class="kw">in</span> text_of_pdfs_cleaned_tokenize_bigrams_v1.items():</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    text_of_pdfs_cleaned_tokenize_bigrams_combined_v1[k] <span class="op">=</span> [[<span class="ss">f"</span><span class="sc">{</span>a<span class="sc">}</span><span class="ss"> </span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">"</span> <span class="cf">for</span> a, b <span class="kw">in</span> sublist] <span class="cf">for</span> sublist <span class="kw">in</span> v]</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>text_of_pdfs_cleaned_tokenize_bigrams_combined_v1[<span class="st">'p2_01'</span>][<span class="dv">0</span>][:<span class="dv">3</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<blockquote class="blockquote">
<p>[‘doi jgim’, ‘jgim global’, ‘global inform’]</p>
</blockquote>
<p>Generate Dictionary and Corpuses for unigrams and bigrams, and save them to file (you can read these files in later runs of the program):</p>
<div id="5f176b74" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_dictionary(text, name):</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">""" </span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="co">    As input takes in the text to build the dictionary for and the name of a .mm file</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span> </span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    dictionary <span class="op">=</span> Dictionary(text)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    corpus <span class="op">=</span> [dictionary.doc2bow(review) <span class="cf">for</span> review <span class="kw">in</span> text] </span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    filename <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">.mm"</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>    MmCorpus.serialize(filename, corpus)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> dictionary, corpus</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="451e1178" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>papers_dictionary_unigrams_v1 <span class="op">=</span> {}</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>papers_corpus_unigrams_v1 <span class="op">=</span> {}</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k, v <span class="kw">in</span> text_of_pdfs_cleaned_tokenize_words_v1.items():</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>    papers_dictionary_unigrams_v1[k] <span class="op">=</span> generate_dictionary(v, <span class="st">'mmcorpus_unigrams'</span>)[<span class="dv">0</span>]</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>    papers_corpus_unigrams_v1[k] <span class="op">=</span> generate_dictionary(v, <span class="st">'mmcorpus_unigrams'</span>)[<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="00bb0cf2" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>papers_dictionary_bigrams_v1 <span class="op">=</span> {}</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>papers_corpus_bigrams_v1 <span class="op">=</span> {}</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k, v <span class="kw">in</span> text_of_pdfs_cleaned_tokenize_bigrams_combined_v1.items():</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    papers_dictionary_bigrams_v1[k] <span class="op">=</span> generate_dictionary(v, <span class="st">'mmcorpus_bigrams'</span>)[<span class="dv">0</span>]</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    papers_corpus_bigrams_v1[k] <span class="op">=</span> generate_dictionary(v, <span class="st">'mmcorpus_bigrams'</span>)[<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Additionally, I combine all the PDFs and run this for the entire Database.</p>
<div id="2de32194" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>entire_database_listoflists_unigrams_v1 <span class="op">=</span> []</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> value <span class="kw">in</span> text_of_pdfs_cleaned_tokenize_words_v1.values():</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    entire_database_listoflists_unigrams_v1.extend(value)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>entire_database_listoflists_bigrams_v1 <span class="op">=</span> []</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> value <span class="kw">in</span> text_of_pdfs_cleaned_tokenize_bigrams_combined_v1.values():</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    entire_database_listoflists_bigrams_v1.extend(value)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="c48103d0" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># database_dictionary_unigrams = {}</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="co"># database_corpus_unigrams = {}</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>database_dictionary_unigrams_v1 <span class="op">=</span> generate_dictionary(entire_database_listoflists_unigrams_v1, <span class="st">'mmcorpus_Database_unigrams_v1'</span>)[<span class="dv">0</span>]</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>database_corpus_unigrams_v1 <span class="op">=</span> generate_dictionary(entire_database_listoflists_unigrams_v1, <span class="st">'mmcorpus_Database_unigrams_v1'</span>)[<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="bc663ba3" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>database_dictionary_bigrams_v1 <span class="op">=</span> generate_dictionary(entire_database_listoflists_bigrams_v1, <span class="st">'mmcorpus_Database_bigrams_v1'</span>)[<span class="dv">0</span>]</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>database_corpus_bigrams_v1 <span class="op">=</span> generate_dictionary(entire_database_listoflists_bigrams_v1, <span class="st">'mmcorpus_Database_bigrams_v1'</span>)[<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Printing top 50 words across the corpus:</p>
<div id="e1f5ca16" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------- START OF CHATGPT CODE ----------------------</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> print_top_50_words(corpus, dictionary):</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    total_word_count <span class="op">=</span> defaultdict(<span class="bu">int</span>)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    word_weights <span class="op">=</span> defaultdict(<span class="bu">float</span>)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> word_id, word_count <span class="kw">in</span> itertools.chain.from_iterable(corpus):</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>        total_word_count[word_id] <span class="op">+=</span> word_count</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>    sorted_tota_words_count <span class="op">=</span> <span class="bu">sorted</span>(total_word_count.items(), key <span class="op">=</span> <span class="kw">lambda</span> w: w[<span class="dv">1</span>], reverse <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    tfidf <span class="op">=</span> TfidfModel(corpus)</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> doc <span class="kw">in</span> corpus:</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>        tfidf_weights <span class="op">=</span> tfidf[doc]  <span class="co"># Calculate TF-IDF for the review</span></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> term_id, weight <span class="kw">in</span> tfidf_weights:</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>            word_weights[term_id] <span class="op">+=</span> weight  <span class="co"># Aggregate the weight for the term</span></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    sorted_word_weights <span class="op">=</span> <span class="bu">sorted</span>(word_weights.items(), key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="dv">1</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Print the top 50 terms with their weights</span></span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>    top_50_words <span class="op">=</span> [(dictionary.get(term_id), weight) <span class="cf">for</span> term_id, weight <span class="kw">in</span> sorted_word_weights[:<span class="dv">50</span>]]</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> word, weight <span class="kw">in</span> top_50_words:</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(word, weight)</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------- </span><span class="re">END</span><span class="co"> OF CHATGPT CODE ----------------------</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Uni-grams over the entire database:</p>
<div id="be4c9de9" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>print_top_50_words(database_corpus_unigrams_v1, database_dictionary_unigrams_v1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<blockquote class="blockquote">
<p>use 1710.4405813502553</p>
<p>al 1500.5918177863637 et 1495.2598944189729 studi 1254.889113401414 servic 1177.5025518831014 research 1155.4801330260996 model 1093.757883374598 intent 1085.622080362571 inform 1035.95718724093 market 1032.669725701611 manag 1020.5243612360091 custom 1011.465319080724 perceiv 975.0912634817644 consum 959.7309079460276 and many more</p>
</blockquote>
<p>Bi-grams over the entire database:</p>
<div id="f0a07cf1" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>print_top_50_words(database_corpus_bigrams_v1, database_dictionary_bigrams_v1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<blockquote class="blockquote">
<p>et al 1065.4586868386625 intern market 424.5870797007975 inform manag 324.417783324221 http doiorg 272.8802285987675 inform system 259.07233958915 intent use 247.3467671477514 behavior intent 207.71672202444856 eas use 206.32538882113823 comput human 183.94284111390388 perceiv use 183.0881496709403 human behavior 179.3628870311971 and many more</p>
</blockquote>
<p>Build an LDA model, but I want to test anywhere from 5 to 15 topic numbers, so I’ll leave this as a parameter to pass to this function. I left the other parameters as is. You of course need to pass in your corpus (text) and dictionary (you created above).</p>
<div id="5720e3e6" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_lda_model(n_topic, corpus_, dictionary_):</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    lda_model <span class="op">=</span> gensim.models.ldamodel.LdaModel(corpus <span class="op">=</span> corpus_,</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>                                              num_topics <span class="op">=</span> n_topic,</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>                                              id2word <span class="op">=</span> dictionary_,</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>                                              random_state <span class="op">=</span> <span class="dv">100</span>,</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>                                              update_every <span class="op">=</span> <span class="dv">1</span>,</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>                                              chunksize <span class="op">=</span> <span class="dv">1000</span>,</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>                                              passes <span class="op">=</span> <span class="dv">10</span>,</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>                                              alpha <span class="op">=</span> <span class="st">'auto'</span>,</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>                                              per_word_topics <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> lda_model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here’s where I train 11 different models passing in different values for number of topics. I save each model in a list.</p>
<div id="2cd8c111" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_models(corpus_, dictionary_):</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>    list_to_hold_models <span class="op">=</span> []</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    topic_n_to_try <span class="op">=</span> [<span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">11</span>, <span class="dv">12</span>, <span class="dv">13</span>, <span class="dv">14</span>, <span class="dv">15</span>]</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(topic_n_to_try)):</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>        list_to_hold_models.insert(i, build_lda_model(topic_n_to_try[i], corpus_, dictionary_))</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> list_to_hold_models</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>You can calculate both perplexity and coherence. Coherence is more straightforward: It’s a measure of how correct your model is. Perplexity, not that difficult, it’s how off you are. So, you want higher coherence, and lower perplexity. It’s easier to just focus on one of them. But for practice, I did both!</p>
<div id="43ed2e12" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_perplexity(model, corpus_):</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>    perplexity <span class="op">=</span> model.log_perplexity(corpus_)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> perplexity</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_coherence(model, text, dictionary_):</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>    coherence_model_lda <span class="op">=</span> CoherenceModel(model <span class="op">=</span> model, texts <span class="op">=</span> text, dictionary <span class="op">=</span> dictionary_, coherence<span class="op">=</span><span class="st">'c_v'</span>)</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>    coherence_lda <span class="op">=</span> coherence_model_lda.get_coherence()</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> coherence_lda</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here’s how to compare models: build a table with columns <code>Num_Topics</code> and values of Coherence and Perplexity for each model.</p>
<div id="716837fe" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_model_comparison_table(list_of_models, corpus_, dictionary_, data):</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>    tracker <span class="op">=</span> <span class="dv">5</span> </span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>    models_perplexity <span class="op">=</span> []</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>    models_coherence <span class="op">=</span> []</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    models_topics <span class="op">=</span> [<span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">11</span>, <span class="dv">12</span>, <span class="dv">13</span>, <span class="dv">14</span>, <span class="dv">15</span>]</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> model <span class="kw">in</span> list_of_models:</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>        models_perplexity.append(calculate_perplexity(model, corpus_))</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>        models_coherence.append(calculate_coherence(model, data, dictionary_))</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>        tracker <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> tracker <span class="op">==</span> <span class="dv">10</span>:</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Successfully generated model comparison table."</span>) </span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>    models_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Num_Topics'</span>: models_topics,</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Coherence'</span>: models_coherence,</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Perplexity'</span>: models_perplexity,</span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> models_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>You can either look at the values, or have this code find you the best. Here, I pick the maximum coherence and minimum perplexity. But, what if it’s two difference values? As in, for example, topic number 5 gives the highest coherence but also the highest perplexity, and topic number 10 gives the lowest perplexity but lower coherence. Which do you choose? Well, I decided they’re both equally as important, so I come up with a score for each topic number that’s just the weighted average of coherence and perplexity. Or, save yourself the headache and just use one metric.</p>
<div id="f6cff882" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> find_best_model(models_df):</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Number of topics with the maximum Coherence is "</span>, models_df.loc[models_df[<span class="st">'Coherence'</span>].idxmax(), <span class="st">'Num_Topics'</span>])</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Number of topics with the minimum Perplexity is "</span>, models_df.loc[models_df[<span class="st">'Perplexity'</span>].idxmin(), <span class="st">'Num_Topics'</span>])</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> models_df.loc[models_df[<span class="st">'Coherence'</span>].idxmax(), <span class="st">'Num_Topics'</span>] <span class="op">==</span> models_df.loc[models_df[<span class="st">'Perplexity'</span>].idxmin(), <span class="st">'Num_Topics'</span>]:</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>        best_model_row <span class="op">=</span> models_df.loc[models_df[<span class="st">'Perplexity'</span>].idxmin()]</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>        best_number_of_topics <span class="op">=</span> best_model_row[<span class="st">'Num_Topics'</span>]</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>        models_df[<span class="st">'Normalized_Perplexity'</span>] <span class="op">=</span> (models_df[<span class="st">'Perplexity'</span>] <span class="op">-</span> models_df[<span class="st">'Perplexity'</span>].<span class="bu">min</span>()) <span class="op">/</span> (models_df[<span class="st">'Perplexity'</span>].<span class="bu">max</span>() <span class="op">-</span> models_df[<span class="st">'Perplexity'</span>].<span class="bu">min</span>())</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>        models_df[<span class="st">'Normalized_Coherence'</span>] <span class="op">=</span> (models_df[<span class="st">'Coherence'</span>] <span class="op">-</span> models_df[<span class="st">'Coherence'</span>].<span class="bu">min</span>()) <span class="op">/</span> (models_df[<span class="st">'Coherence'</span>].<span class="bu">max</span>() <span class="op">-</span> models_df[<span class="st">'Coherence'</span>].<span class="bu">min</span>())</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>        models_df[<span class="st">'Inverted_Perplexity'</span>] <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> models_df[<span class="st">'Normalized_Perplexity'</span>] <span class="co"># because smaller is better</span></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>        weight_preplexity <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>        weight_coherence <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>        models_df[<span class="st">'Score'</span>] <span class="op">=</span> weight_coherence <span class="op">*</span> models_df[<span class="st">'Normalized_Coherence'</span>] <span class="op">+</span> weight_preplexity <span class="op">*</span> models_df[<span class="st">'Inverted_Perplexity'</span>]</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>        best_model_row <span class="op">=</span> models_df.loc[models_df[<span class="st">'Score'</span>].idxmax()]</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>        best_number_of_topics <span class="op">=</span> best_model_row[<span class="st">'Num_Topics'</span>]</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(best_model_row)</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>                                       </span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_model_row, best_number_of_topics</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>                                                                                                     </span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>                                                                                                </span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> pick_best_model(num, m):</span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>    <span class="co">""" </span></span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a><span class="co">    Model inputs are: </span></span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a><span class="co">        num = best number of topics found according to find_best_model()</span></span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a><span class="co">        m = list of models </span></span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a>    model_index <span class="op">=</span> num <span class="op">-</span> <span class="dv">5</span> </span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a>    model_index <span class="op">=</span> <span class="bu">int</span>(model_index)</span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a>                                       </span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a>    best_model <span class="op">=</span> m[model_index]</span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a>                                       </span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_model  </span>
<span id="cb31-39"><a href="#cb31-39" aria-hidden="true" tabindex="-1"></a>                                                                  </span>
<span id="cb31-40"><a href="#cb31-40" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> print_topics(model, corpus):</span>
<span id="cb31-41"><a href="#cb31-41" aria-hidden="true" tabindex="-1"></a>    pprint(model.print_topics())</span>
<span id="cb31-42"><a href="#cb31-42" aria-hidden="true" tabindex="-1"></a>    doc_lda <span class="op">=</span> model[corpus]</span>
<span id="cb31-43"><a href="#cb31-43" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-44"><a href="#cb31-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> doc_lda</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="topic-modeling---unigrams" class="level4">
<h4 class="anchored" data-anchor-id="topic-modeling---unigrams">Topic Modeling - Unigrams</h4>
<div id="e29231dd" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>unigram_models_v1 <span class="op">=</span> train_models(database_corpus_unigrams_v1, database_dictionary_unigrams_v1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here are the results for unigram models:</p>
<div id="aea377e8" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>unigram_model_comparison_v1 <span class="op">=</span> build_model_comparison_table(unigram_models_v1, database_corpus_unigrams_v1, database_dictionary_unigrams_v1, entire_database_listoflists_unigrams_v1)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>unigram_model_comparison_v1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Num_Topics</th>
<th>Coherence</th>
<th>Perplexity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>5</td>
<td>0.436565</td>
</tr>
<tr class="even">
<td>1</td>
<td>6</td>
<td>0.413618</td>
</tr>
<tr class="odd">
<td>2</td>
<td>7</td>
<td>0.469700</td>
</tr>
<tr class="even">
<td>3</td>
<td>8</td>
<td>0.400105</td>
</tr>
<tr class="odd">
<td>4</td>
<td>9</td>
<td>0.452116</td>
</tr>
<tr class="even">
<td>5</td>
<td>10</td>
<td>0.420971</td>
</tr>
<tr class="odd">
<td>6</td>
<td>11</td>
<td>0.446276</td>
</tr>
<tr class="even">
<td>7</td>
<td>12</td>
<td>0.454530</td>
</tr>
<tr class="odd">
<td>8</td>
<td>13</td>
<td>0.409933</td>
</tr>
<tr class="even">
<td>9</td>
<td>14</td>
<td>0.418211</td>
</tr>
<tr class="odd">
<td>10</td>
<td>15</td>
<td>0.406770</td>
</tr>
</tbody>
</table>
<div id="baeebf01" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>unigram_best_row_v1 <span class="op">=</span> find_best_model(unigram_model_comparison_v1)[<span class="dv">0</span>]</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>unigram_best_n_topics_v1 <span class="op">=</span> find_best_model(unigram_model_comparison_v1)[<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<blockquote class="blockquote">
<p>Number of topics with the maximum Coherence is 7 Number of topics with the minimum Perplexity is 15 Num_Topics 12.000000 Coherence 0.454530 Perplexity -9.011387 Normalized_Perplexity 0.636029 Normalized_Coherence 0.782020 Inverted_Perplexity 0.363971 Score 0.572996 Name: 7, dtype: float64 Number of topics with the maximum Coherence is 7 Number of topics with the minimum Perplexity is 15 Num_Topics 12.000000 Coherence 0.454530 Perplexity -9.011387 Normalized_Perplexity 0.636029 Normalized_Coherence 0.782020 Inverted_Perplexity 0.363971 Score 0.572996 Name: 7, dtype: float64</p>
</blockquote>
<div id="9dbb0030" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>unigram_best_model_v1 <span class="op">=</span> pick_best_model(unigram_best_n_topics_v1, unigram_models_v1)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best Unigram model is (V1):"</span>, unigram_best_model_v1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<blockquote class="blockquote">
<p>Best Unigram model is (V1): LdaModel(num_terms=27200, num_topics=12, decay=0.5, chunksize=1000)</p>
</blockquote>
</section>
<section id="topic-modeling---bigrams" class="level4">
<h4 class="anchored" data-anchor-id="topic-modeling---bigrams">Topic Modeling - Bigrams</h4>
<div id="b288475e" class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>bigram_models_v1 <span class="op">=</span> train_models(database_corpus_bigrams_v1, database_dictionary_bigrams_v1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>And the bigrams:</p>
<div id="5ffcbd6e" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>bigram_model_comparison_v1 <span class="op">=</span> build_model_comparison_table(bigram_models_v1, database_corpus_bigrams_v1, database_dictionary_bigrams_v1, entire_database_listoflists_bigrams_v1)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>bigram_model_comparison_v1</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Num_Topics</th>
<th>Coherence</th>
<th>Perplexity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>5</td>
<td>0.558434</td>
</tr>
<tr class="even">
<td>1</td>
<td>6</td>
<td>0.535400</td>
</tr>
<tr class="odd">
<td>2</td>
<td>7</td>
<td>0.542287</td>
</tr>
<tr class="even">
<td>3</td>
<td>8</td>
<td>0.515335</td>
</tr>
<tr class="odd">
<td>4</td>
<td>9</td>
<td>0.523767</td>
</tr>
<tr class="even">
<td>5</td>
<td>10</td>
<td>0.526290</td>
</tr>
<tr class="odd">
<td>6</td>
<td>11</td>
<td>0.523879</td>
</tr>
<tr class="even">
<td>7</td>
<td>12</td>
<td>0.513803</td>
</tr>
<tr class="odd">
<td>8</td>
<td>13</td>
<td>0.510867</td>
</tr>
<tr class="even">
<td>9</td>
<td>14</td>
<td>0.554809</td>
</tr>
<tr class="odd">
<td>10</td>
<td>15</td>
<td>0.582336</td>
</tr>
</tbody>
</table>
<div id="955e6dc7" class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>bigram_best_row_v1 <span class="op">=</span> find_best_model(bigram_model_comparison_v1)[<span class="dv">0</span>]</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>bigram_best_n_topics_v1 <span class="op">=</span> find_best_model(bigram_model_comparison_v1)[<span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<blockquote class="blockquote">
<p>Number of topics with the maximum Coherence is 15 Number of topics with the minimum Perplexity is 15 Num_Topics 15.000000 Coherence 0.582336 Perplexity -24.581214 Name: 10, dtype: float64 Number of topics with the maximum Coherence is 15 Number of topics with the minimum Perplexity is 15 Num_Topics 15.000000 Coherence 0.582336 Perplexity -24.581214 Name: 10, dtype: float64</p>
</blockquote>
<div id="3f943cf2" class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>bigram_best_model_v1 <span class="op">=</span> pick_best_model(bigram_best_n_topics_v1, bigram_models_v1)</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best Unigram model is (V1):"</span>, bigram_best_model_v1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<blockquote class="blockquote">
<p>Best Unigram model is (V1): LdaModel(num_terms=306163, num_topics=15, decay=0.5, chunksize=1000)</p>
</blockquote>
</section>
<section id="pick-best-model" class="level4">
<h4 class="anchored" data-anchor-id="pick-best-model">Pick Best Model</h4>
<p>This is different from my dissertation because I actually didn’t upload all the pdf’s here, and also I’m looking at both scores where I only looked at Coherence. Also, 15 topics is way too many.</p>
<div id="b49c393c" class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> model_score(p, c, wp <span class="op">=</span> <span class="fl">0.5</span>, wc <span class="op">=</span> <span class="fl">0.5</span>):</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">""" Calculates model score with 0.5 weights as default"""</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>    score <span class="op">=</span> (<span class="dv">1</span> <span class="op">-</span> p) <span class="op">*</span> wp <span class="op">+</span> c <span class="op">*</span> wc </span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> score</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="ece4c625" class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best unigram model's score is (V1):"</span>, model_score(<span class="op">-</span><span class="fl">9.011387</span>,<span class="fl">0.454530</span>))</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best bigram model's score is (V1):"</span>, model_score(<span class="op">-</span><span class="fl">24.581214</span>,<span class="fl">0.582336</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<table class="caption-top table">
<thead>
<tr class="header">
<th>NGRAM</th>
<th>Perplexity</th>
<th>Coherence</th>
<th># of topics</th>
<th>Score</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>UNI</td>
<td><span class="math inline">-9.011387</span></td>
<td><span class="math inline">0.454530</span></td>
<td><span class="math inline">12</span></td>
<td><span class="math inline">5.2329585</span></td>
</tr>
<tr class="even">
<td>BI</td>
<td><span class="math inline">-24.581214</span></td>
<td><span class="math inline">0.582336</span></td>
<td><span class="math inline">15</span></td>
<td><span class="math inline">13.081775</span></td>
</tr>
</tbody>
</table>
<p>The best model overall is therefore <code>bigram_best_model</code>.</p>
<p>I chose bigrams, but went with 8-9 topics.</p>
<div id="d82ef66b" class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>best_topic_model_v1 <span class="op">=</span> bigram_best_model_v1</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>number_of_topics <span class="op">=</span> <span class="dv">8</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="3cbf3456" class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>print_topics(best_topic_model_v1, database_corpus_bigrams_v1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="./images/topics_table.png" class="img-fluid"></p>
</section>
</section>
<section id="topic-modeling-using-keywords" class="level3">
<h3 class="anchored" data-anchor-id="topic-modeling-using-keywords">Topic Modeling using Keywords</h3>
<div id="302d0766" class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>keywordsDf <span class="op">=</span> df.loc[:,<span class="st">'K1'</span>:<span class="st">'K10'</span>]</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>keywords_across_db <span class="op">=</span> keywordsDf.values.flatten().tolist()</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(keywords_across_db)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="6f579e81" class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>empty_or_na_count <span class="op">=</span> <span class="bu">sum</span>(<span class="dv">1</span> <span class="cf">for</span> x <span class="kw">in</span> keywords_across_db <span class="cf">if</span> x <span class="kw">in</span> [<span class="va">None</span>, <span class="st">""</span>, <span class="st">' '</span>] <span class="kw">or</span> (<span class="bu">isinstance</span>(x, <span class="bu">float</span>) <span class="kw">and</span> math.isnan(x)))</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of empty or NA values: </span><span class="sc">{</span>empty_or_na_count<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>keywords_across_db <span class="op">=</span> [x <span class="cf">for</span> x <span class="kw">in</span> keywords_across_db <span class="cf">if</span> x <span class="kw">not</span> <span class="kw">in</span> [<span class="va">None</span>, <span class="st">""</span>, <span class="st">' '</span>] <span class="kw">and</span> <span class="kw">not</span> (<span class="bu">isinstance</span>(x, <span class="bu">float</span>) <span class="kw">and</span> math.isnan(x))]</span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>keywords_across_db_nodup <span class="op">=</span> <span class="bu">list</span>(<span class="bu">set</span>(keywords_across_db))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="d8928fcc" class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> BertTokenizer, BertModel</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> BertTokenizer.from_pretrained(<span class="st">'bert-base-uncased'</span>)</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>model_bert <span class="op">=</span> BertModel.from_pretrained(<span class="st">'bert-base-uncased'</span>)</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_embedding(text):</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> tokenizer(text, return_tensors<span class="op">=</span><span class="st">'pt'</span>, truncation<span class="op">=</span><span class="va">True</span>, padding<span class="op">=</span><span class="va">True</span>, max_length<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model_bert(<span class="op">**</span>inputs)</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> outputs.last_hidden_state.mean(dim<span class="op">=</span><span class="dv">1</span>).squeeze().numpy()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="8226e031" class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> print_clusters(n_clusters, list_of_words):</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>    clusters <span class="op">=</span> {i: [] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_clusters)}</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> word, label <span class="kw">in</span> <span class="bu">zip</span>(list_of_words, labels):</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>        clusters[label].append(word)</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> label, words <span class="kw">in</span> clusters.items():</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Cluster </span><span class="sc">{</span>label<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> word <span class="kw">in</span> words:</span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>word<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Explain clusters</span></span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Cluster explanations based on semantics and ideas:"</span>)</span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> label, words <span class="kw">in</span> clusters.items():</span>
<span id="cb47-15"><a href="#cb47-15" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Cluster </span><span class="sc">{</span>label<span class="sc">}</span><span class="ss"> might be related to:"</span>)</span>
<span id="cb47-16"><a href="#cb47-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> word <span class="kw">in</span> words:</span>
<span id="cb47-17"><a href="#cb47-17" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>word<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb47-18"><a href="#cb47-18" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="4f45916a" class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch </span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>keyword_embeddings <span class="op">=</span> np.array([get_embedding(phrase) <span class="cf">for</span> phrase <span class="kw">in</span> keywords_across_db_nodup])</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>n_clusters <span class="op">=</span> number_of_topics</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters <span class="op">=</span> n_clusters, random_state <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>kmeans.fit(keyword_embeddings)</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> kmeans.labels_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="7abf7a51" class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>print_clusters(n_clusters, keywords_across_db_nodup)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="./images/keyclusters.png" class="img-fluid"></p>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb50" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Topic Modeling" </span></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "Yekta Amirkhalili"</span></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "today"</span></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span><span class="co"> </span></span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a><span class="co">  html: </span></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: false</span></span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true</span></span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a><span class="co">    self-contained: false</span></span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a><span class="co">    execute:</span></span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a><span class="co">      eval: false </span></span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a><span class="co">      echo: true</span></span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a><span class="co">      warning: false</span></span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a><span class="co">      message: false</span></span>
<span id="cb50-15"><a href="#cb50-15" aria-hidden="true" tabindex="-1"></a><span class="co">      error: false</span></span>
<span id="cb50-16"><a href="#cb50-16" aria-hidden="true" tabindex="-1"></a><span class="co">      results: 'asis'</span></span>
<span id="cb50-17"><a href="#cb50-17" aria-hidden="true" tabindex="-1"></a><span class="co">    #css: style.css</span></span>
<span id="cb50-18"><a href="#cb50-18" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb50-19"><a href="#cb50-19" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- CSS CHANGES --&gt;</span></span>
<span id="cb50-20"><a href="#cb50-20" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">style</span><span class="dt">&gt;</span></span>
<span id="cb50-21"><a href="#cb50-21" aria-hidden="true" tabindex="-1"></a><span class="fu">.quarto-title</span> h1<span class="fu">.title</span> {</span>
<span id="cb50-22"><a href="#cb50-22" aria-hidden="true" tabindex="-1"></a>  <span class="kw">font-size</span><span class="ch">:</span> <span class="dv">1.5</span><span class="dt">rem</span><span class="op">;</span> </span>
<span id="cb50-23"><a href="#cb50-23" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb50-24"><a href="#cb50-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-25"><a href="#cb50-25" aria-hidden="true" tabindex="-1"></a>h2{</span>
<span id="cb50-26"><a href="#cb50-26" aria-hidden="true" tabindex="-1"></a>    <span class="kw">font-size</span><span class="ch">:</span> <span class="dv">1.2</span><span class="dt">rem</span><span class="op">;</span></span>
<span id="cb50-27"><a href="#cb50-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">background-color</span><span class="ch">:</span><span class="fu">rgba(</span><span class="dv">128</span><span class="op">,</span> <span class="dv">170</span><span class="op">,</span> <span class="dv">156</span><span class="op">,</span> <span class="dv">0.48</span><span class="fu">)</span><span class="op">;</span></span>
<span id="cb50-28"><a href="#cb50-28" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb50-29"><a href="#cb50-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-30"><a href="#cb50-30" aria-hidden="true" tabindex="-1"></a><span class="fu">.future-idea-box</span> {</span>
<span id="cb50-31"><a href="#cb50-31" aria-hidden="true" tabindex="-1"></a>  <span class="kw">border</span><span class="ch">:</span> <span class="dv">2</span><span class="dt">px</span> <span class="dv">solid</span> <span class="fu">var(</span><span class="va">--quarto-hl-header-color</span><span class="op">,</span> <span class="cn">#86bdab</span><span class="fu">)</span><span class="op">;</span> <span class="co">/* Uses Quarto header color variable or fallback */</span></span>
<span id="cb50-32"><a href="#cb50-32" aria-hidden="true" tabindex="-1"></a>  <span class="kw">border-radius</span><span class="ch">:</span> <span class="dv">8</span><span class="dt">px</span><span class="op">;</span></span>
<span id="cb50-33"><a href="#cb50-33" aria-hidden="true" tabindex="-1"></a>  <span class="kw">padding</span><span class="ch">:</span> <span class="dv">1</span><span class="dt">em</span><span class="op">;</span></span>
<span id="cb50-34"><a href="#cb50-34" aria-hidden="true" tabindex="-1"></a>  <span class="kw">margin</span><span class="ch">:</span> <span class="dv">1</span><span class="dt">em</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb50-35"><a href="#cb50-35" aria-hidden="true" tabindex="-1"></a>  <span class="kw">background</span><span class="ch">:</span> <span class="cn">#f9f9fc</span><span class="op">;</span></span>
<span id="cb50-36"><a href="#cb50-36" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb50-37"><a href="#cb50-37" aria-hidden="true" tabindex="-1"></a><span class="fu">.future-idea-title</span> {</span>
<span id="cb50-38"><a href="#cb50-38" aria-hidden="true" tabindex="-1"></a>  <span class="kw">font-weight</span><span class="ch">:</span> <span class="dv">bold</span><span class="op">;</span></span>
<span id="cb50-39"><a href="#cb50-39" aria-hidden="true" tabindex="-1"></a>  <span class="kw">color</span><span class="ch">:</span> <span class="fu">var(</span><span class="va">--quarto-hl-header-color</span><span class="op">,</span><span class="fu">rgb(</span><span class="dv">111</span><span class="op">,</span> <span class="dv">172</span><span class="op">,</span> <span class="dv">152</span><span class="fu">))</span><span class="op">;</span></span>
<span id="cb50-40"><a href="#cb50-40" aria-hidden="true" tabindex="-1"></a>  <span class="kw">margin-bottom</span><span class="ch">:</span> <span class="dv">0.5</span><span class="dt">em</span><span class="op">;</span></span>
<span id="cb50-41"><a href="#cb50-41" aria-hidden="true" tabindex="-1"></a>  <span class="kw">font-size</span><span class="ch">:</span> <span class="dv">1.1</span><span class="dt">em</span><span class="op">;</span></span>
<span id="cb50-42"><a href="#cb50-42" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb50-43"><a href="#cb50-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-44"><a href="#cb50-44" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;/</span><span class="kw">style</span><span class="dt">&gt;</span></span>
<span id="cb50-45"><a href="#cb50-45" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- CSS CHANGES --&gt;</span></span>
<span id="cb50-46"><a href="#cb50-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-47"><a href="#cb50-47" aria-hidden="true" tabindex="-1"></a><span class="fu">## Part 0. Jupyter Notebook </span></span>
<span id="cb50-48"><a href="#cb50-48" aria-hidden="true" tabindex="-1"></a>If you want to run the entire code, use the Jupyter notebook on my github page. </span>
<span id="cb50-49"><a href="#cb50-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-50"><a href="#cb50-50" aria-hidden="true" tabindex="-1"></a><span class="fu">## Part 1. </span></span>
<span id="cb50-51"><a href="#cb50-51" aria-hidden="true" tabindex="-1"></a>First things first, we need a bunch of libraries. </span>
<span id="cb50-52"><a href="#cb50-52" aria-hidden="true" tabindex="-1"></a>Since I am not familiar with <span class="co">[</span><span class="ot">Docker</span><span class="co">](https://www.docker.com/)</span>, I couldn't resolve the package dependencies. </span>
<span id="cb50-53"><a href="#cb50-53" aria-hidden="true" tabindex="-1"></a>This took so much time for me and I finally managed to fix it with this specific configuration. </span>
<span id="cb50-54"><a href="#cb50-54" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_1}</span></span>
<span id="cb50-55"><a href="#cb50-55" aria-hidden="true" tabindex="-1"></a>__requires__<span class="op">=</span> <span class="st">'scipy==1.12.0'</span></span>
<span id="cb50-56"><a href="#cb50-56" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy</span>
<span id="cb50-57"><a href="#cb50-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-58"><a href="#cb50-58" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(scipy.__version__)</span>
<span id="cb50-59"><a href="#cb50-59" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-60"><a href="#cb50-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-61"><a href="#cb50-61" aria-hidden="true" tabindex="-1"></a>The imports look scary, but a lot of them I won't even use, just added them because I wanted to try things:</span>
<span id="cb50-62"><a href="#cb50-62" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_2}</span></span>
<span id="cb50-63"><a href="#cb50-63" aria-hidden="true" tabindex="-1"></a><span class="co"># general python imports </span></span>
<span id="cb50-64"><a href="#cb50-64" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> string</span>
<span id="cb50-65"><a href="#cb50-65" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb50-66"><a href="#cb50-66" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb50-67"><a href="#cb50-67" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb50-68"><a href="#cb50-68" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np </span>
<span id="cb50-69"><a href="#cb50-69" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy</span>
<span id="cb50-70"><a href="#cb50-70" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> itertools</span>
<span id="cb50-71"><a href="#cb50-71" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> textract</span>
<span id="cb50-72"><a href="#cb50-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-73"><a href="#cb50-73" aria-hidden="true" tabindex="-1"></a><span class="co"># NLT imports </span></span>
<span id="cb50-74"><a href="#cb50-74" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nltk</span>
<span id="cb50-75"><a href="#cb50-75" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk <span class="im">import</span> pos_tag</span>
<span id="cb50-76"><a href="#cb50-76" aria-hidden="true" tabindex="-1"></a><span class="co">#from nltk.tokenize import regexp_tokenize</span></span>
<span id="cb50-77"><a href="#cb50-77" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> word_tokenize</span>
<span id="cb50-78"><a href="#cb50-78" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> sent_tokenize</span>
<span id="cb50-79"><a href="#cb50-79" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> stopwords</span>
<span id="cb50-80"><a href="#cb50-80" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.stem <span class="im">import</span> WordNetLemmatizer</span>
<span id="cb50-81"><a href="#cb50-81" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.corpus <span class="im">import</span> wordnet</span>
<span id="cb50-82"><a href="#cb50-82" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.stem.porter <span class="im">import</span> PorterStemmer</span>
<span id="cb50-83"><a href="#cb50-83" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.util <span class="im">import</span> ngrams</span>
<span id="cb50-84"><a href="#cb50-84" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nltk.tokenize <span class="im">import</span> RegexpTokenizer</span>
<span id="cb50-85"><a href="#cb50-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-86"><a href="#cb50-86" aria-hidden="true" tabindex="-1"></a><span class="co"># SKLEARN </span></span>
<span id="cb50-87"><a href="#cb50-87" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> metrics</span>
<span id="cb50-88"><a href="#cb50-88" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> neighbors</span>
<span id="cb50-89"><a href="#cb50-89" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> CountVectorizer</span>
<span id="cb50-90"><a href="#cb50-90" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb50-91"><a href="#cb50-91" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction.text <span class="im">import</span> TfidfVectorizer</span>
<span id="cb50-92"><a href="#cb50-92" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb50-93"><a href="#cb50-93" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb50-94"><a href="#cb50-94" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</span>
<span id="cb50-95"><a href="#cb50-95" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> r2_score</span>
<span id="cb50-96"><a href="#cb50-96" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.ensemble import RandomForestClassifier</span></span>
<span id="cb50-97"><a href="#cb50-97" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.metrics import classification_report</span></span>
<span id="cb50-98"><a href="#cb50-98" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.naive_bayes import MultinomialNB</span></span>
<span id="cb50-99"><a href="#cb50-99" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.neighbors import NearestNeighbors</span></span>
<span id="cb50-100"><a href="#cb50-100" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.preprocessing import LabelEncoder</span></span>
<span id="cb50-101"><a href="#cb50-101" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.metrics import classification_report,confusion_matrix,accuracy_score</span></span>
<span id="cb50-102"><a href="#cb50-102" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.naive_bayes import (</span></span>
<span id="cb50-103"><a href="#cb50-103" aria-hidden="true" tabindex="-1"></a><span class="co">#     BernoulliNB,</span></span>
<span id="cb50-104"><a href="#cb50-104" aria-hidden="true" tabindex="-1"></a><span class="co">#     ComplementNB,</span></span>
<span id="cb50-105"><a href="#cb50-105" aria-hidden="true" tabindex="-1"></a><span class="co">#     MultinomialNB,</span></span>
<span id="cb50-106"><a href="#cb50-106" aria-hidden="true" tabindex="-1"></a><span class="co"># )</span></span>
<span id="cb50-107"><a href="#cb50-107" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.neighbors import KNeighborsClassifier</span></span>
<span id="cb50-108"><a href="#cb50-108" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.tree import DecisionTreeClassifier</span></span>
<span id="cb50-109"><a href="#cb50-109" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.ensemble import RandomForestClassifier</span></span>
<span id="cb50-110"><a href="#cb50-110" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.linear_model import LogisticRegression</span></span>
<span id="cb50-111"><a href="#cb50-111" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.neural_network import MLPClassifier</span></span>
<span id="cb50-112"><a href="#cb50-112" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis</span></span>
<span id="cb50-113"><a href="#cb50-113" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.decomposition import LatentDirichletAllocation</span></span>
<span id="cb50-114"><a href="#cb50-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-115"><a href="#cb50-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-116"><a href="#cb50-116" aria-hidden="true" tabindex="-1"></a><span class="co"># GENSIM imports </span></span>
<span id="cb50-117"><a href="#cb50-117" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gensim</span>
<span id="cb50-118"><a href="#cb50-118" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models <span class="im">import</span> Phrases</span>
<span id="cb50-119"><a href="#cb50-119" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models.phrases <span class="im">import</span> Phraser</span>
<span id="cb50-120"><a href="#cb50-120" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.corpora.dictionary <span class="im">import</span> Dictionary</span>
<span id="cb50-121"><a href="#cb50-121" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.corpora <span class="im">import</span> MmCorpus</span>
<span id="cb50-122"><a href="#cb50-122" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models.tfidfmodel <span class="im">import</span> TfidfModel</span>
<span id="cb50-123"><a href="#cb50-123" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models <span class="im">import</span> CoherenceModel</span>
<span id="cb50-124"><a href="#cb50-124" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> gensim.models <span class="im">import</span> KeyedVectors</span>
<span id="cb50-125"><a href="#cb50-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-126"><a href="#cb50-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-127"><a href="#cb50-127" aria-hidden="true" tabindex="-1"></a><span class="co"># PyLDAvis imports </span></span>
<span id="cb50-128"><a href="#cb50-128" aria-hidden="true" tabindex="-1"></a><span class="co"># import pyLDAvis</span></span>
<span id="cb50-129"><a href="#cb50-129" aria-hidden="true" tabindex="-1"></a><span class="co"># import pyLDAvis.gensim_models as gensimvis</span></span>
<span id="cb50-130"><a href="#cb50-130" aria-hidden="true" tabindex="-1"></a><span class="co"># import pyLDAvis.gensim</span></span>
<span id="cb50-131"><a href="#cb50-131" aria-hidden="true" tabindex="-1"></a><span class="co"># import pyLDAvis.gensim_models</span></span>
<span id="cb50-132"><a href="#cb50-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-133"><a href="#cb50-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-134"><a href="#cb50-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-135"><a href="#cb50-135" aria-hidden="true" tabindex="-1"></a><span class="co"># MISC imports </span></span>
<span id="cb50-136"><a href="#cb50-136" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb50-137"><a href="#cb50-137" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> defaultdict</span>
<span id="cb50-138"><a href="#cb50-138" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> string <span class="im">import</span> punctuation</span>
<span id="cb50-139"><a href="#cb50-139" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pprint <span class="im">import</span> pprint</span>
<span id="cb50-140"><a href="#cb50-140" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> triu</span>
<span id="cb50-141"><a href="#cb50-141" aria-hidden="true" tabindex="-1"></a><span class="co">#from scipy.linalg.special_matrices import triu</span></span>
<span id="cb50-142"><a href="#cb50-142" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.sparse <span class="im">import</span> csr_matrix</span>
<span id="cb50-143"><a href="#cb50-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-144"><a href="#cb50-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-145"><a href="#cb50-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-146"><a href="#cb50-146" aria-hidden="true" tabindex="-1"></a><span class="co"># TRANSFORMERS </span></span>
<span id="cb50-147"><a href="#cb50-147" aria-hidden="true" tabindex="-1"></a><span class="co">#import torch</span></span>
<span id="cb50-148"><a href="#cb50-148" aria-hidden="true" tabindex="-1"></a><span class="co">#import tensorflow as tf</span></span>
<span id="cb50-149"><a href="#cb50-149" aria-hidden="true" tabindex="-1"></a><span class="co">#from transformers import BertTokenizer, BertModel</span></span>
<span id="cb50-150"><a href="#cb50-150" aria-hidden="true" tabindex="-1"></a><span class="co">#from tensorflow.keras.models import Sequential</span></span>
<span id="cb50-151"><a href="#cb50-151" aria-hidden="true" tabindex="-1"></a><span class="co">#from tensorflow.keras.preprocessing.text import Tokenizer</span></span>
<span id="cb50-152"><a href="#cb50-152" aria-hidden="true" tabindex="-1"></a><span class="co">#from tensorflow.keras.preprocessing.sequence import pad_sequences</span></span>
<span id="cb50-153"><a href="#cb50-153" aria-hidden="true" tabindex="-1"></a><span class="co">#from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D</span></span>
<span id="cb50-154"><a href="#cb50-154" aria-hidden="true" tabindex="-1"></a><span class="co">#from tensorflow.keras.layers import LeakyReLU</span></span>
<span id="cb50-155"><a href="#cb50-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-156"><a href="#cb50-156" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> fitz  <span class="co"># PyMuPDF</span></span>
<span id="cb50-157"><a href="#cb50-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-158"><a href="#cb50-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-159"><a href="#cb50-159" aria-hidden="true" tabindex="-1"></a><span class="co"># MATPLOT </span></span>
<span id="cb50-160"><a href="#cb50-160" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb50-161"><a href="#cb50-161" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb50-162"><a href="#cb50-162" aria-hidden="true" tabindex="-1"></a><span class="co">#%matplotlib inline # do this if you're in jupyter, I still don't know why tho </span></span>
<span id="cb50-163"><a href="#cb50-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-164"><a href="#cb50-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-165"><a href="#cb50-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-166"><a href="#cb50-166" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-167"><a href="#cb50-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-168"><a href="#cb50-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-169"><a href="#cb50-169" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_3}</span></span>
<span id="cb50-170"><a href="#cb50-170" aria-hidden="true" tabindex="-1"></a><span class="co"># only run once</span></span>
<span id="cb50-171"><a href="#cb50-171" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'stopwords'</span>)</span>
<span id="cb50-172"><a href="#cb50-172" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'punkt'</span>)</span>
<span id="cb50-173"><a href="#cb50-173" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'wordnet'</span>)</span>
<span id="cb50-174"><a href="#cb50-174" aria-hidden="true" tabindex="-1"></a>nltk.download(<span class="st">'punkt_tab'</span>)</span>
<span id="cb50-175"><a href="#cb50-175" aria-hidden="true" tabindex="-1"></a><span class="co">#nltk.download('omw-1.4')  # Optional for better language support</span></span>
<span id="cb50-176"><a href="#cb50-176" aria-hidden="true" tabindex="-1"></a><span class="co">#nltk.download('averaged_perceptron_tagger')  # For POS tagging</span></span>
<span id="cb50-177"><a href="#cb50-177" aria-hidden="true" tabindex="-1"></a><span class="co">#nltk.download('averaged_perceptron_tagger_eng')</span></span>
<span id="cb50-178"><a href="#cb50-178" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-179"><a href="#cb50-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-180"><a href="#cb50-180" aria-hidden="true" tabindex="-1"></a><span class="fu">### CLEANING AND PRE-PROCESSING DATA </span></span>
<span id="cb50-181"><a href="#cb50-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-182"><a href="#cb50-182" aria-hidden="true" tabindex="-1"></a>I downloaded the pdf of all the papers (143), reading them and extracting meta data based on the following:</span>
<span id="cb50-183"><a href="#cb50-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-184"><a href="#cb50-184" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_4 name="meta_data_extraction"}</span></span>
<span id="cb50-185"><a href="#cb50-185" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false </span></span>
<span id="cb50-186"><a href="#cb50-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-187"><a href="#cb50-187" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np </span>
<span id="cb50-188"><a href="#cb50-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-189"><a href="#cb50-189" aria-hidden="true" tabindex="-1"></a>database <span class="op">=</span> np.array([</span>
<span id="cb50-190"><a href="#cb50-190" aria-hidden="true" tabindex="-1"></a>    {</span>
<span id="cb50-191"><a href="#cb50-191" aria-hidden="true" tabindex="-1"></a>        <span class="st">'id'</span>: <span class="st">'string'</span>, <span class="co"># unique identifier for the paper following convention P2_#number </span></span>
<span id="cb50-192"><a href="#cb50-192" aria-hidden="true" tabindex="-1"></a>        <span class="st">'title'</span>: <span class="st">'string'</span>, <span class="co"># title of the paper</span></span>
<span id="cb50-193"><a href="#cb50-193" aria-hidden="true" tabindex="-1"></a>        <span class="st">'AffiliationCountry'</span>: <span class="st">'string'</span> , <span class="co">#name of country the study was conducted in,</span></span>
<span id="cb50-194"><a href="#cb50-194" aria-hidden="true" tabindex="-1"></a>        <span class="st">'year'</span>: <span class="dv">2018</span><span class="op">-</span><span class="dv">2024</span>, <span class="co"># year of publication a value between 2018 and 2024</span></span>
<span id="cb50-195"><a href="#cb50-195" aria-hidden="true" tabindex="-1"></a>        <span class="st">'journal'</span>: <span class="st">'string'</span>, <span class="co"># name of the journal the paper was published in</span></span>
<span id="cb50-196"><a href="#cb50-196" aria-hidden="true" tabindex="-1"></a>        <span class="st">'citations'</span>: <span class="dv">0</span><span class="op">-</span><span class="dv">1000</span>, <span class="co"># number of citations the paper has received - not reported in the paper </span></span>
<span id="cb50-197"><a href="#cb50-197" aria-hidden="true" tabindex="-1"></a>        <span class="st">'year_since'</span>: <span class="dv">3</span>, <span class="co"># number of years since publication - not reported in the paper </span></span>
<span id="cb50-198"><a href="#cb50-198" aria-hidden="true" tabindex="-1"></a>        <span class="st">'cpy'</span>: <span class="dv">0</span>, <span class="co"># number of citations per year - not reported in the paper </span></span>
<span id="cb50-199"><a href="#cb50-199" aria-hidden="true" tabindex="-1"></a>        <span class="st">'keywords'</span>: [<span class="st">'TAM'</span>, <span class="st">'mbanking'</span>, <span class="st">'awareness'</span>], <span class="co"># list of keywords, broken into K1-K10</span></span>
<span id="cb50-200"><a href="#cb50-200" aria-hidden="true" tabindex="-1"></a>        <span class="st">'abstract'</span>: <span class="st">'string'</span>, <span class="co"># abstract of the paper </span></span>
<span id="cb50-201"><a href="#cb50-201" aria-hidden="true" tabindex="-1"></a>        <span class="st">'F'</span>: [<span class="st">'perceived usefulness'</span>], <span class="co"># factors significant in the study, broken into F1-F9 </span></span>
<span id="cb50-202"><a href="#cb50-202" aria-hidden="true" tabindex="-1"></a>        <span class="st">'FN'</span>: [<span class="st">'another factor'</span>], <span class="co"># factors not significant in the study, broken into FNS1-FNS4 </span></span>
<span id="cb50-203"><a href="#cb50-203" aria-hidden="true" tabindex="-1"></a>        <span class="st">'limit'</span>: [<span class="st">'geographical context'</span>], <span class="co"># limitations of the study, broken into LIMIT1-LIMIT3 </span></span>
<span id="cb50-204"><a href="#cb50-204" aria-hidden="true" tabindex="-1"></a>        <span class="st">'typeofResearch'</span>: <span class="st">'string'</span>, <span class="co"># type of research conducted in the study </span></span>
<span id="cb50-205"><a href="#cb50-205" aria-hidden="true" tabindex="-1"></a>        <span class="st">'methods'</span>: [<span class="st">'regression analysis'</span>], <span class="co"># methods used in the study, broken into METHOD1-METHOD4</span></span>
<span id="cb50-206"><a href="#cb50-206" aria-hidden="true" tabindex="-1"></a>        <span class="st">'theory'</span>: [<span class="st">'TAM'</span>] <span class="co"># theories used in the study, broken into THEORY1-THEORY4</span></span>
<span id="cb50-207"><a href="#cb50-207" aria-hidden="true" tabindex="-1"></a>        <span class="st">'sampleSize'</span>: <span class="dv">100</span>, <span class="co"># sample size of the study </span></span>
<span id="cb50-208"><a href="#cb50-208" aria-hidden="true" tabindex="-1"></a>        <span class="st">'tech'</span>: <span class="st">'string'</span>, <span class="co"># main technology studied </span></span>
<span id="cb50-209"><a href="#cb50-209" aria-hidden="true" tabindex="-1"></a>        <span class="st">'man_theme'</span>: <span class="st">'string'</span>, <span class="co"># Theme manually assigned by me </span></span>
<span id="cb50-210"><a href="#cb50-210" aria-hidden="true" tabindex="-1"></a>        <span class="st">'algo_theme'</span>: <span class="st">'string'</span>, <span class="co"># Theme assigned by the algorithm </span></span>
<span id="cb50-211"><a href="#cb50-211" aria-hidden="true" tabindex="-1"></a>        <span class="st">'decision_Theme'</span>: <span class="st">'string'</span>, <span class="co"># Final theme of the paper  </span></span>
<span id="cb50-212"><a href="#cb50-212" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Score_Sig'</span>: <span class="fl">0.0</span>, <span class="co"># % of significance for factors </span></span>
<span id="cb50-213"><a href="#cb50-213" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Score_NOT_Sig'</span>: <span class="fl">0.0</span>, <span class="co"># % of non-significance for factors</span></span>
<span id="cb50-214"><a href="#cb50-214" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb50-215"><a href="#cb50-215" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb50-216"><a href="#cb50-216" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-217"><a href="#cb50-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-218"><a href="#cb50-218" aria-hidden="true" tabindex="-1"></a>:::: {.future-idea-box}</span>
<span id="cb50-219"><a href="#cb50-219" aria-hidden="true" tabindex="-1"></a>::: {.future-idea-title} </span>
<span id="cb50-220"><a href="#cb50-220" aria-hidden="true" tabindex="-1"></a>Idea for future</span>
<span id="cb50-221"><a href="#cb50-221" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb50-222"><a href="#cb50-222" aria-hidden="true" tabindex="-1"></a>🤖 Build an Agentic AI application that automates this process. </span>
<span id="cb50-223"><a href="#cb50-223" aria-hidden="true" tabindex="-1"></a>::::</span>
<span id="cb50-224"><a href="#cb50-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-225"><a href="#cb50-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-226"><a href="#cb50-226" aria-hidden="true" tabindex="-1"></a>The following procedures are implemented for Data Cleaning: </span>
<span id="cb50-227"><a href="#cb50-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-228"><a href="#cb50-228" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Turn everything into lower case </span>
<span id="cb50-229"><a href="#cb50-229" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Remove stopwords + additional stopwords such as "bank", "banking", "banks", "mobile", "mbank", "mbanking", "m-bank", "online", "digital", "adoption", "theory", "app", "application"</span>
<span id="cb50-230"><a href="#cb50-230" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Remove punctuation </span>
<span id="cb50-231"><a href="#cb50-231" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Lemming/Stemming  </span>
<span id="cb50-232"><a href="#cb50-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-233"><a href="#cb50-233" aria-hidden="true" tabindex="-1"></a>Grabbing the names of the pdf files (you can also do this from the terminal, and have the results be written to a <span class="in">`.txt`</span> file). </span>
<span id="cb50-234"><a href="#cb50-234" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_5}</span></span>
<span id="cb50-235"><a href="#cb50-235" aria-hidden="true" tabindex="-1"></a>pdf_directory <span class="op">=</span> <span class="st">"./pdfs/"</span></span>
<span id="cb50-236"><a href="#cb50-236" aria-hidden="true" tabindex="-1"></a>all_files <span class="op">=</span> os.listdir(pdf_directory)</span>
<span id="cb50-237"><a href="#cb50-237" aria-hidden="true" tabindex="-1"></a>pdf_files <span class="op">=</span> [<span class="bu">file</span> <span class="cf">for</span> <span class="bu">file</span> <span class="kw">in</span> all_files <span class="cf">if</span> <span class="bu">file</span>.endswith(<span class="st">'.pdf'</span>)]</span>
<span id="cb50-238"><a href="#cb50-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-239"><a href="#cb50-239" aria-hidden="true" tabindex="-1"></a>output_file <span class="op">=</span> <span class="st">"pdf_file_names.txt"</span></span>
<span id="cb50-240"><a href="#cb50-240" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> <span class="bu">open</span>(output_file, <span class="st">"w"</span>) <span class="im">as</span> f:</span>
<span id="cb50-241"><a href="#cb50-241" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> pdf <span class="kw">in</span> pdf_files:</span>
<span id="cb50-242"><a href="#cb50-242" aria-hidden="true" tabindex="-1"></a>        f.write(pdf <span class="op">+</span> <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb50-243"><a href="#cb50-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-244"><a href="#cb50-244" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"PDF file names have been saved to </span><span class="sc">{</span>output_file<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb50-245"><a href="#cb50-245" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-246"><a href="#cb50-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-247"><a href="#cb50-247" aria-hidden="true" tabindex="-1"></a>Then saving them in a python dictionary: </span>
<span id="cb50-248"><a href="#cb50-248" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_6}</span></span>
<span id="cb50-249"><a href="#cb50-249" aria-hidden="true" tabindex="-1"></a>name_of_pdfs <span class="op">=</span> {</span>
<span id="cb50-250"><a href="#cb50-250" aria-hidden="true" tabindex="-1"></a>    <span class="st">'p2_101'</span>: <span class="st">"Okocha and Awele Adibi - 2020 - Mobile banking adoption by business executives in.pdf"</span>,</span>
<span id="cb50-251"><a href="#cb50-251" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ... </span></span>
<span id="cb50-252"><a href="#cb50-252" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb50-253"><a href="#cb50-253" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb50-254"><a href="#cb50-254" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-255"><a href="#cb50-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-256"><a href="#cb50-256" aria-hidden="true" tabindex="-1"></a>Extract text: </span>
<span id="cb50-257"><a href="#cb50-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-258"><a href="#cb50-258" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_7}</span></span>
<span id="cb50-259"><a href="#cb50-259" aria-hidden="true" tabindex="-1"></a><span class="co">#version one using PyMuPDF - there's also textract </span></span>
<span id="cb50-260"><a href="#cb50-260" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> extract_text_from_pdf(filename):</span>
<span id="cb50-261"><a href="#cb50-261" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> <span class="st">""</span></span>
<span id="cb50-262"><a href="#cb50-262" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb50-263"><a href="#cb50-263" aria-hidden="true" tabindex="-1"></a>        doc <span class="op">=</span> fitz.<span class="bu">open</span>(filename)</span>
<span id="cb50-264"><a href="#cb50-264" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> page_num <span class="kw">in</span> <span class="bu">range</span>(doc.page_count):</span>
<span id="cb50-265"><a href="#cb50-265" aria-hidden="true" tabindex="-1"></a>            page <span class="op">=</span> doc.load_page(page_num)</span>
<span id="cb50-266"><a href="#cb50-266" aria-hidden="true" tabindex="-1"></a>            text <span class="op">+=</span> page.get_text()</span>
<span id="cb50-267"><a href="#cb50-267" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> <span class="pp">Exception</span> <span class="im">as</span> e:</span>
<span id="cb50-268"><a href="#cb50-268" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Error reading </span><span class="sc">{</span>filename<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>e<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb50-269"><a href="#cb50-269" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> text</span>
<span id="cb50-270"><a href="#cb50-270" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-271"><a href="#cb50-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-272"><a href="#cb50-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-273"><a href="#cb50-273" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_8}</span></span>
<span id="cb50-274"><a href="#cb50-274" aria-hidden="true" tabindex="-1"></a>text_of_pdfs_v1 <span class="op">=</span> {}</span>
<span id="cb50-275"><a href="#cb50-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-276"><a href="#cb50-276" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> paper_id, filename <span class="kw">in</span> name_of_pdfs.items():</span>
<span id="cb50-277"><a href="#cb50-277" aria-hidden="true" tabindex="-1"></a>    text <span class="op">=</span> extract_text_from_pdf(filename)</span>
<span id="cb50-278"><a href="#cb50-278" aria-hidden="true" tabindex="-1"></a>    text_of_pdfs_v1[paper_id] <span class="op">=</span> text</span>
<span id="cb50-279"><a href="#cb50-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-280"><a href="#cb50-280" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Print the extracted text from the first PDF</span></span>
<span id="cb50-281"><a href="#cb50-281" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> paper_id, text <span class="kw">in</span> text_of_pdfs_v1.items():</span>
<span id="cb50-282"><a href="#cb50-282" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Text from </span><span class="sc">{</span>paper_id<span class="sc">}</span><span class="ss"> (</span><span class="sc">{</span>name_of_pdfs[paper_id]<span class="sc">}</span><span class="ss">):"</span>)</span>
<span id="cb50-283"><a href="#cb50-283" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(text[:<span class="dv">500</span>])  <span class="co"># Print the first 500 characters of the text</span></span>
<span id="cb50-284"><a href="#cb50-284" aria-hidden="true" tabindex="-1"></a>    <span class="cf">break</span></span>
<span id="cb50-285"><a href="#cb50-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-286"><a href="#cb50-286" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-287"><a href="#cb50-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-288"><a href="#cb50-288" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Text from p2_101 (Okocha and Awele Adibi - 2020 - Mobile banking adoption by business executives in .pdf):</span></span>
<span id="cb50-289"><a href="#cb50-289" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Mobile banking adoption by business executives in Nigeria</span></span>
<span id="cb50-290"><a href="#cb50-290" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Foluke Olabisi Okocha1* and Vera Awele Adibi2</span></span>
<span id="cb50-291"><a href="#cb50-291" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 1Centre for Learning Resources, Landmark University, Nigeria</span></span>
<span id="cb50-292"><a href="#cb50-292" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; 2Doctoral student, University of Ibadan, Nigeria</span></span>
<span id="cb50-293"><a href="#cb50-293" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; *Corresponding author email: dada.foluke@lmu.edu.ng, folukedada@yahoo.com</span></span>
<span id="cb50-294"><a href="#cb50-294" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Challenges with the adoption of mobile banking technologies are best understood by studies on adoption. This however</span></span>
<span id="cb50-295"><a href="#cb50-295" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; requires understanding the factors that inﬂuence its adoption in a given region. Technology Acc</span></span>
<span id="cb50-296"><a href="#cb50-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-297"><a href="#cb50-297" aria-hidden="true" tabindex="-1"></a>Clean text:</span>
<span id="cb50-298"><a href="#cb50-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-299"><a href="#cb50-299" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_9}</span></span>
<span id="cb50-300"><a href="#cb50-300" aria-hidden="true" tabindex="-1"></a>stop_words <span class="op">=</span> stopwords.words(<span class="st">'english'</span>)</span>
<span id="cb50-301"><a href="#cb50-301" aria-hidden="true" tabindex="-1"></a>stop_words.extend([<span class="st">"bank"</span>, <span class="st">"banking"</span>, <span class="st">"banks"</span>, </span>
<span id="cb50-302"><a href="#cb50-302" aria-hidden="true" tabindex="-1"></a>                   <span class="st">"mobile"</span>, <span class="st">"mbank"</span>, <span class="st">"mbanking"</span>, <span class="st">"m-bank"</span>, <span class="st">"m bank"</span>,</span>
<span id="cb50-303"><a href="#cb50-303" aria-hidden="true" tabindex="-1"></a>                   <span class="st">"adoption"</span>, <span class="st">"acceptance"</span>, <span class="st">"accept"</span>, <span class="st">"theory"</span>, <span class="st">"technology"</span>, </span>
<span id="cb50-304"><a href="#cb50-304" aria-hidden="true" tabindex="-1"></a>                   <span class="st">"purpose"</span>, <span class="st">"result"</span>, <span class="st">"method"</span>, <span class="co">#from abstracts </span></span>
<span id="cb50-305"><a href="#cb50-305" aria-hidden="true" tabindex="-1"></a>                   <span class="st">"journal"</span>, <span class="st">"volume"</span>, <span class="st">"pp"</span>, <span class="st">"no"</span>, <span class="co">#from journal information </span></span>
<span id="cb50-306"><a href="#cb50-306" aria-hidden="true" tabindex="-1"></a>                   <span class="st">"theory"</span>, <span class="st">"app"</span>, <span class="st">"application"</span>, <span class="st">"usage"</span>, <span class="st">"model"</span>])</span>
<span id="cb50-307"><a href="#cb50-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-308"><a href="#cb50-308" aria-hidden="true" tabindex="-1"></a>stemmer <span class="op">=</span> PorterStemmer()</span>
<span id="cb50-309"><a href="#cb50-309" aria-hidden="true" tabindex="-1"></a>lemmatizer <span class="op">=</span> WordNetLemmatizer()</span>
<span id="cb50-310"><a href="#cb50-310" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-311"><a href="#cb50-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-312"><a href="#cb50-312" aria-hidden="true" tabindex="-1"></a>This is just one of the cleaning functions: </span>
<span id="cb50-313"><a href="#cb50-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-314"><a href="#cb50-314" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_10}</span></span>
<span id="cb50-315"><a href="#cb50-315" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> preprocess_Dict(dct):</span>
<span id="cb50-316"><a href="#cb50-316" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> k, v <span class="kw">in</span> dct.items():</span>
<span id="cb50-317"><a href="#cb50-317" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(v, <span class="bu">list</span>):</span>
<span id="cb50-318"><a href="#cb50-318" aria-hidden="true" tabindex="-1"></a>            processed_list <span class="op">=</span> []</span>
<span id="cb50-319"><a href="#cb50-319" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> item <span class="kw">in</span> v:</span>
<span id="cb50-320"><a href="#cb50-320" aria-hidden="true" tabindex="-1"></a>                item <span class="op">=</span> item.lower()</span>
<span id="cb50-321"><a href="#cb50-321" aria-hidden="true" tabindex="-1"></a>                item <span class="op">=</span> re.sub(<span class="vs">r'http</span><span class="dv">\S</span><span class="op">+</span><span class="vs">www</span><span class="dv">\S</span><span class="op">+</span><span class="vs">@</span><span class="dv">\S</span><span class="op">+</span><span class="vs">'</span>, <span class="st">''</span>, item)</span>
<span id="cb50-322"><a href="#cb50-322" aria-hidden="true" tabindex="-1"></a>                item <span class="op">=</span> re.sub(<span class="vs">r'</span><span class="kw">(</span><span class="fu">?&lt;</span><span class="vs">=</span><span class="dv">\w</span><span class="kw">)</span><span class="vs">-</span><span class="ex">(</span><span class="fu">?=</span><span class="dv">\w</span><span class="ex">)</span><span class="vs">'</span>, <span class="st">' '</span>, item)</span>
<span id="cb50-323"><a href="#cb50-323" aria-hidden="true" tabindex="-1"></a>                item <span class="op">=</span> re.sub(<span class="vs">r'</span><span class="pp">[^a-z0-9</span><span class="dv">\s</span><span class="ch">\n</span><span class="pp">]</span><span class="vs">'</span>, <span class="st">''</span>, item)</span>
<span id="cb50-324"><a href="#cb50-324" aria-hidden="true" tabindex="-1"></a>                item <span class="op">=</span> re.sub(<span class="vs">r'</span><span class="dv">\s</span><span class="op">+</span><span class="vs">'</span>, <span class="st">' '</span>, item).strip()</span>
<span id="cb50-325"><a href="#cb50-325" aria-hidden="true" tabindex="-1"></a>                item <span class="op">=</span> re.sub(<span class="vs">r'</span><span class="dv">\d</span><span class="op">+</span><span class="vs">'</span>, <span class="st">''</span>, item).strip()</span>
<span id="cb50-326"><a href="#cb50-326" aria-hidden="true" tabindex="-1"></a>                item <span class="op">=</span> <span class="st">" "</span>.join([word <span class="cf">for</span> word <span class="kw">in</span> item.split() <span class="cf">if</span> word <span class="kw">not</span> <span class="kw">in</span> stop_words])</span>
<span id="cb50-327"><a href="#cb50-327" aria-hidden="true" tabindex="-1"></a>                item <span class="op">=</span> <span class="st">" "</span>.join([stemmer.stem(word) <span class="cf">for</span> word <span class="kw">in</span> item.split()])</span>
<span id="cb50-328"><a href="#cb50-328" aria-hidden="true" tabindex="-1"></a>                processed_list.append(item)</span>
<span id="cb50-329"><a href="#cb50-329" aria-hidden="true" tabindex="-1"></a>            dct[k] <span class="op">=</span> processed_list</span>
<span id="cb50-330"><a href="#cb50-330" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb50-331"><a href="#cb50-331" aria-hidden="true" tabindex="-1"></a>            v <span class="op">=</span> v.lower()</span>
<span id="cb50-332"><a href="#cb50-332" aria-hidden="true" tabindex="-1"></a>            v <span class="op">=</span> re.sub(<span class="vs">r'http</span><span class="dv">\S</span><span class="op">+</span><span class="vs">www</span><span class="dv">\S</span><span class="op">+</span><span class="vs">@</span><span class="dv">\S</span><span class="op">+</span><span class="vs">'</span>, <span class="st">''</span>, v)</span>
<span id="cb50-333"><a href="#cb50-333" aria-hidden="true" tabindex="-1"></a>            v <span class="op">=</span> re.sub(<span class="vs">r'</span><span class="kw">(</span><span class="fu">?&lt;</span><span class="vs">=</span><span class="dv">\w</span><span class="kw">)</span><span class="vs">-</span><span class="ex">(</span><span class="fu">?=</span><span class="dv">\w</span><span class="ex">)</span><span class="vs">'</span>, <span class="st">' '</span>, v)</span>
<span id="cb50-334"><a href="#cb50-334" aria-hidden="true" tabindex="-1"></a>            v <span class="op">=</span> re.sub(<span class="vs">r'</span><span class="pp">[^a-z0-9</span><span class="dv">\s</span><span class="ch">\n</span><span class="pp">]</span><span class="vs">'</span>, <span class="st">''</span>, v)</span>
<span id="cb50-335"><a href="#cb50-335" aria-hidden="true" tabindex="-1"></a>            v <span class="op">=</span> re.sub(<span class="vs">r'</span><span class="dv">\s</span><span class="op">+</span><span class="vs">'</span>, <span class="st">' '</span>, v).strip()</span>
<span id="cb50-336"><a href="#cb50-336" aria-hidden="true" tabindex="-1"></a>            v <span class="op">=</span> re.sub(<span class="vs">r'</span><span class="dv">\d</span><span class="op">+</span><span class="vs">'</span>, <span class="st">''</span>, v).strip()</span>
<span id="cb50-337"><a href="#cb50-337" aria-hidden="true" tabindex="-1"></a>            v <span class="op">=</span> <span class="st">" "</span>.join([word <span class="cf">for</span> word <span class="kw">in</span> v.split() <span class="cf">if</span> word <span class="kw">not</span> <span class="kw">in</span> stop_words])</span>
<span id="cb50-338"><a href="#cb50-338" aria-hidden="true" tabindex="-1"></a>            v <span class="op">=</span> <span class="st">" "</span>.join([stemmer.stem(word) <span class="cf">for</span> word <span class="kw">in</span> v.split()])</span>
<span id="cb50-339"><a href="#cb50-339" aria-hidden="true" tabindex="-1"></a>            dct[k] <span class="op">=</span> v</span>
<span id="cb50-340"><a href="#cb50-340" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> dct</span>
<span id="cb50-341"><a href="#cb50-341" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-342"><a href="#cb50-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-343"><a href="#cb50-343" aria-hidden="true" tabindex="-1"></a>Sentence Tokenizer: </span>
<span id="cb50-344"><a href="#cb50-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-345"><a href="#cb50-345" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_11}</span></span>
<span id="cb50-346"><a href="#cb50-346" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tokenizeToSentences(doc):</span>
<span id="cb50-347"><a href="#cb50-347" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> k, v <span class="kw">in</span> doc.items():</span>
<span id="cb50-348"><a href="#cb50-348" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb50-349"><a href="#cb50-349" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(v, <span class="bu">bytes</span>):</span>
<span id="cb50-350"><a href="#cb50-350" aria-hidden="true" tabindex="-1"></a>            v <span class="op">=</span> v.decode(<span class="st">'utf-8'</span>)</span>
<span id="cb50-351"><a href="#cb50-351" aria-hidden="true" tabindex="-1"></a>          </span>
<span id="cb50-352"><a href="#cb50-352" aria-hidden="true" tabindex="-1"></a>        v <span class="op">=</span> v.lower()</span>
<span id="cb50-353"><a href="#cb50-353" aria-hidden="true" tabindex="-1"></a>        v <span class="op">=</span> v.replace(<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>, <span class="st">' '</span>)</span>
<span id="cb50-354"><a href="#cb50-354" aria-hidden="true" tabindex="-1"></a>        v <span class="op">=</span> re.sub(<span class="vs">r'http</span><span class="dv">\S</span><span class="op">+</span><span class="vs">www</span><span class="dv">\S</span><span class="op">+</span><span class="vs">@</span><span class="dv">\S</span><span class="op">+</span><span class="vs">'</span>, <span class="st">''</span>, v)</span>
<span id="cb50-355"><a href="#cb50-355" aria-hidden="true" tabindex="-1"></a>        <span class="co">#v = " ".join([str(s) for s in v])</span></span>
<span id="cb50-356"><a href="#cb50-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-357"><a href="#cb50-357" aria-hidden="true" tabindex="-1"></a>        v <span class="op">=</span> sent_tokenize(v)</span>
<span id="cb50-358"><a href="#cb50-358" aria-hidden="true" tabindex="-1"></a>        doc[k] <span class="op">=</span> v</span>
<span id="cb50-359"><a href="#cb50-359" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb50-360"><a href="#cb50-360" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> doc</span>
<span id="cb50-361"><a href="#cb50-361" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-362"><a href="#cb50-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-363"><a href="#cb50-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-364"><a href="#cb50-364" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_12}</span></span>
<span id="cb50-365"><a href="#cb50-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-366"><a href="#cb50-366" aria-hidden="true" tabindex="-1"></a>text_of_pdfs_uncleaned_tokenizedSentences_v1 <span class="op">=</span> tokenizeToSentences(text_of_pdfs_v1)</span>
<span id="cb50-367"><a href="#cb50-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-368"><a href="#cb50-368" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-369"><a href="#cb50-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-370"><a href="#cb50-370" aria-hidden="true" tabindex="-1"></a>Build uni and bi-grams: </span>
<span id="cb50-371"><a href="#cb50-371" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_13}</span></span>
<span id="cb50-372"><a href="#cb50-372" aria-hidden="true" tabindex="-1"></a>text_of_pdfs_uncleaned_tokenize_words_v1 <span class="op">=</span> {}</span>
<span id="cb50-373"><a href="#cb50-373" aria-hidden="true" tabindex="-1"></a>text_of_pdfs_uncleaned_tokenize_bigrams_v1 <span class="op">=</span> {}</span>
<span id="cb50-374"><a href="#cb50-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-375"><a href="#cb50-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-376"><a href="#cb50-376" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k, v <span class="kw">in</span> text_of_pdfs_uncleaned_tokenizedSentences_v1.items():</span>
<span id="cb50-377"><a href="#cb50-377" aria-hidden="true" tabindex="-1"></a>    <span class="co">#v is a list of sentences </span></span>
<span id="cb50-378"><a href="#cb50-378" aria-hidden="true" tabindex="-1"></a>    text_of_pdfs_uncleaned_tokenize_words_v1[k] <span class="op">=</span> [word_tokenize(s) <span class="cf">for</span> s <span class="kw">in</span> v] <span class="co">#list of lists </span></span>
<span id="cb50-379"><a href="#cb50-379" aria-hidden="true" tabindex="-1"></a>    text_of_pdfs_uncleaned_tokenize_bigrams_v1[k] <span class="op">=</span> [<span class="bu">list</span>(ngrams(sentence, <span class="dv">2</span>)) <span class="cf">for</span> sentence <span class="kw">in</span> text_of_pdfs_uncleaned_tokenize_words_v1[k]] </span>
<span id="cb50-380"><a href="#cb50-380" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb50-381"><a href="#cb50-381" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-382"><a href="#cb50-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-383"><a href="#cb50-383" aria-hidden="true" tabindex="-1"></a>Clean: </span>
<span id="cb50-384"><a href="#cb50-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-385"><a href="#cb50-385" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_14}</span></span>
<span id="cb50-386"><a href="#cb50-386" aria-hidden="true" tabindex="-1"></a>text_of_pdfs_cleaned_tokenize_words_v1 <span class="op">=</span> {}</span>
<span id="cb50-387"><a href="#cb50-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-388"><a href="#cb50-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-389"><a href="#cb50-389" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k, v <span class="kw">in</span> text_of_pdfs_uncleaned_tokenize_words_v1.items():</span>
<span id="cb50-390"><a href="#cb50-390" aria-hidden="true" tabindex="-1"></a>    <span class="co"># v is a list of lists - where each outer list is a sentence, and the inner list is the words in that sentence. </span></span>
<span id="cb50-391"><a href="#cb50-391" aria-hidden="true" tabindex="-1"></a>    text_of_pdfs_cleaned_tokenize_words_v1[k] <span class="op">=</span> preprocess_listOfLists(v)</span>
<span id="cb50-392"><a href="#cb50-392" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb50-393"><a href="#cb50-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-394"><a href="#cb50-394" aria-hidden="true" tabindex="-1"></a>text_of_pdfs_cleaned_tokenize_bigrams_v1 <span class="op">=</span> {}</span>
<span id="cb50-395"><a href="#cb50-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-396"><a href="#cb50-396" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k, v <span class="kw">in</span> text_of_pdfs_cleaned_tokenize_words_v1.items():</span>
<span id="cb50-397"><a href="#cb50-397" aria-hidden="true" tabindex="-1"></a>    text_of_pdfs_cleaned_tokenize_bigrams_v1[k] <span class="op">=</span> [<span class="bu">list</span>(ngrams(sentence, <span class="dv">2</span>)) <span class="cf">for</span> sentence <span class="kw">in</span> v]</span>
<span id="cb50-398"><a href="#cb50-398" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb50-399"><a href="#cb50-399" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-400"><a href="#cb50-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-401"><a href="#cb50-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-402"><a href="#cb50-402" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_15}</span></span>
<span id="cb50-403"><a href="#cb50-403" aria-hidden="true" tabindex="-1"></a>text_of_pdfs_cleaned_tokenize_words_v1[<span class="st">'p2_01'</span>][<span class="dv">0</span>][:<span class="dv">3</span>]</span>
<span id="cb50-404"><a href="#cb50-404" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-405"><a href="#cb50-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-406"><a href="#cb50-406" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">'doi', 'jgim', 'global'</span><span class="co">]</span></span>
<span id="cb50-407"><a href="#cb50-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-408"><a href="#cb50-408" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_16}</span></span>
<span id="cb50-409"><a href="#cb50-409" aria-hidden="true" tabindex="-1"></a>text_of_pdfs_cleaned_tokenize_bigrams_v1[<span class="st">'p2_01'</span>][<span class="dv">0</span>][:<span class="dv">3</span>]</span>
<span id="cb50-410"><a href="#cb50-410" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-411"><a href="#cb50-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-412"><a href="#cb50-412" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">('doi', 'jgim'), ('jgim', 'global'), ('global', 'inform')</span><span class="co">]</span></span>
<span id="cb50-413"><a href="#cb50-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-414"><a href="#cb50-414" aria-hidden="true" tabindex="-1"></a>Stich the bi-grams together:</span>
<span id="cb50-415"><a href="#cb50-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-416"><a href="#cb50-416" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_17}</span></span>
<span id="cb50-417"><a href="#cb50-417" aria-hidden="true" tabindex="-1"></a>text_of_pdfs_cleaned_tokenize_bigrams_combined_v1 <span class="op">=</span> {}</span>
<span id="cb50-418"><a href="#cb50-418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-419"><a href="#cb50-419" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k, v <span class="kw">in</span> text_of_pdfs_cleaned_tokenize_bigrams_v1.items():</span>
<span id="cb50-420"><a href="#cb50-420" aria-hidden="true" tabindex="-1"></a>    text_of_pdfs_cleaned_tokenize_bigrams_combined_v1[k] <span class="op">=</span> [[<span class="ss">f"</span><span class="sc">{</span>a<span class="sc">}</span><span class="ss"> </span><span class="sc">{</span>b<span class="sc">}</span><span class="ss">"</span> <span class="cf">for</span> a, b <span class="kw">in</span> sublist] <span class="cf">for</span> sublist <span class="kw">in</span> v]</span>
<span id="cb50-421"><a href="#cb50-421" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb50-422"><a href="#cb50-422" aria-hidden="true" tabindex="-1"></a>text_of_pdfs_cleaned_tokenize_bigrams_combined_v1[<span class="st">'p2_01'</span>][<span class="dv">0</span>][:<span class="dv">3</span>]</span>
<span id="cb50-423"><a href="#cb50-423" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-424"><a href="#cb50-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-425"><a href="#cb50-425" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span><span class="co">[</span><span class="ot">'doi jgim', 'jgim global', 'global inform'</span><span class="co">]</span></span>
<span id="cb50-426"><a href="#cb50-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-427"><a href="#cb50-427" aria-hidden="true" tabindex="-1"></a>Generate Dictionary and Corpuses for unigrams and bigrams, and save them to file (you can read these files in later runs of the program):</span>
<span id="cb50-428"><a href="#cb50-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-429"><a href="#cb50-429" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_18}</span></span>
<span id="cb50-430"><a href="#cb50-430" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_dictionary(text, name):</span>
<span id="cb50-431"><a href="#cb50-431" aria-hidden="true" tabindex="-1"></a>    <span class="co">""" </span></span>
<span id="cb50-432"><a href="#cb50-432" aria-hidden="true" tabindex="-1"></a><span class="co">    As input takes in the text to build the dictionary for and the name of a .mm file</span></span>
<span id="cb50-433"><a href="#cb50-433" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span> </span>
<span id="cb50-434"><a href="#cb50-434" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb50-435"><a href="#cb50-435" aria-hidden="true" tabindex="-1"></a>    dictionary <span class="op">=</span> Dictionary(text)</span>
<span id="cb50-436"><a href="#cb50-436" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb50-437"><a href="#cb50-437" aria-hidden="true" tabindex="-1"></a>    corpus <span class="op">=</span> [dictionary.doc2bow(review) <span class="cf">for</span> review <span class="kw">in</span> text] </span>
<span id="cb50-438"><a href="#cb50-438" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb50-439"><a href="#cb50-439" aria-hidden="true" tabindex="-1"></a>    filename <span class="op">=</span> <span class="ss">f"</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">.mm"</span></span>
<span id="cb50-440"><a href="#cb50-440" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb50-441"><a href="#cb50-441" aria-hidden="true" tabindex="-1"></a>    MmCorpus.serialize(filename, corpus)</span>
<span id="cb50-442"><a href="#cb50-442" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb50-443"><a href="#cb50-443" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> dictionary, corpus</span>
<span id="cb50-444"><a href="#cb50-444" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-445"><a href="#cb50-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-446"><a href="#cb50-446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-447"><a href="#cb50-447" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_19}</span></span>
<span id="cb50-448"><a href="#cb50-448" aria-hidden="true" tabindex="-1"></a>papers_dictionary_unigrams_v1 <span class="op">=</span> {}</span>
<span id="cb50-449"><a href="#cb50-449" aria-hidden="true" tabindex="-1"></a>papers_corpus_unigrams_v1 <span class="op">=</span> {}</span>
<span id="cb50-450"><a href="#cb50-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-451"><a href="#cb50-451" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k, v <span class="kw">in</span> text_of_pdfs_cleaned_tokenize_words_v1.items():</span>
<span id="cb50-452"><a href="#cb50-452" aria-hidden="true" tabindex="-1"></a>    papers_dictionary_unigrams_v1[k] <span class="op">=</span> generate_dictionary(v, <span class="st">'mmcorpus_unigrams'</span>)[<span class="dv">0</span>]</span>
<span id="cb50-453"><a href="#cb50-453" aria-hidden="true" tabindex="-1"></a>    papers_corpus_unigrams_v1[k] <span class="op">=</span> generate_dictionary(v, <span class="st">'mmcorpus_unigrams'</span>)[<span class="dv">1</span>]</span>
<span id="cb50-454"><a href="#cb50-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-455"><a href="#cb50-455" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-456"><a href="#cb50-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-457"><a href="#cb50-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-458"><a href="#cb50-458" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_20}</span></span>
<span id="cb50-459"><a href="#cb50-459" aria-hidden="true" tabindex="-1"></a>papers_dictionary_bigrams_v1 <span class="op">=</span> {}</span>
<span id="cb50-460"><a href="#cb50-460" aria-hidden="true" tabindex="-1"></a>papers_corpus_bigrams_v1 <span class="op">=</span> {}</span>
<span id="cb50-461"><a href="#cb50-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-462"><a href="#cb50-462" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k, v <span class="kw">in</span> text_of_pdfs_cleaned_tokenize_bigrams_combined_v1.items():</span>
<span id="cb50-463"><a href="#cb50-463" aria-hidden="true" tabindex="-1"></a>    papers_dictionary_bigrams_v1[k] <span class="op">=</span> generate_dictionary(v, <span class="st">'mmcorpus_bigrams'</span>)[<span class="dv">0</span>]</span>
<span id="cb50-464"><a href="#cb50-464" aria-hidden="true" tabindex="-1"></a>    papers_corpus_bigrams_v1[k] <span class="op">=</span> generate_dictionary(v, <span class="st">'mmcorpus_bigrams'</span>)[<span class="dv">1</span>]</span>
<span id="cb50-465"><a href="#cb50-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-466"><a href="#cb50-466" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-467"><a href="#cb50-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-468"><a href="#cb50-468" aria-hidden="true" tabindex="-1"></a>Additionally, I combine all the PDFs and run this for the entire Database. </span>
<span id="cb50-469"><a href="#cb50-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-470"><a href="#cb50-470" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_21}</span></span>
<span id="cb50-471"><a href="#cb50-471" aria-hidden="true" tabindex="-1"></a>entire_database_listoflists_unigrams_v1 <span class="op">=</span> []</span>
<span id="cb50-472"><a href="#cb50-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-473"><a href="#cb50-473" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> value <span class="kw">in</span> text_of_pdfs_cleaned_tokenize_words_v1.values():</span>
<span id="cb50-474"><a href="#cb50-474" aria-hidden="true" tabindex="-1"></a>    entire_database_listoflists_unigrams_v1.extend(value)</span>
<span id="cb50-475"><a href="#cb50-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-476"><a href="#cb50-476" aria-hidden="true" tabindex="-1"></a>entire_database_listoflists_bigrams_v1 <span class="op">=</span> []</span>
<span id="cb50-477"><a href="#cb50-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-478"><a href="#cb50-478" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> value <span class="kw">in</span> text_of_pdfs_cleaned_tokenize_bigrams_combined_v1.values():</span>
<span id="cb50-479"><a href="#cb50-479" aria-hidden="true" tabindex="-1"></a>    entire_database_listoflists_bigrams_v1.extend(value)</span>
<span id="cb50-480"><a href="#cb50-480" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-481"><a href="#cb50-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-482"><a href="#cb50-482" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_22}</span></span>
<span id="cb50-483"><a href="#cb50-483" aria-hidden="true" tabindex="-1"></a><span class="co"># database_dictionary_unigrams = {}</span></span>
<span id="cb50-484"><a href="#cb50-484" aria-hidden="true" tabindex="-1"></a><span class="co"># database_corpus_unigrams = {}</span></span>
<span id="cb50-485"><a href="#cb50-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-486"><a href="#cb50-486" aria-hidden="true" tabindex="-1"></a>database_dictionary_unigrams_v1 <span class="op">=</span> generate_dictionary(entire_database_listoflists_unigrams_v1, <span class="st">'mmcorpus_Database_unigrams_v1'</span>)[<span class="dv">0</span>]</span>
<span id="cb50-487"><a href="#cb50-487" aria-hidden="true" tabindex="-1"></a>database_corpus_unigrams_v1 <span class="op">=</span> generate_dictionary(entire_database_listoflists_unigrams_v1, <span class="st">'mmcorpus_Database_unigrams_v1'</span>)[<span class="dv">1</span>]</span>
<span id="cb50-488"><a href="#cb50-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-489"><a href="#cb50-489" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-490"><a href="#cb50-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-491"><a href="#cb50-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-492"><a href="#cb50-492" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_23}</span></span>
<span id="cb50-493"><a href="#cb50-493" aria-hidden="true" tabindex="-1"></a>database_dictionary_bigrams_v1 <span class="op">=</span> generate_dictionary(entire_database_listoflists_bigrams_v1, <span class="st">'mmcorpus_Database_bigrams_v1'</span>)[<span class="dv">0</span>]</span>
<span id="cb50-494"><a href="#cb50-494" aria-hidden="true" tabindex="-1"></a>database_corpus_bigrams_v1 <span class="op">=</span> generate_dictionary(entire_database_listoflists_bigrams_v1, <span class="st">'mmcorpus_Database_bigrams_v1'</span>)[<span class="dv">1</span>]</span>
<span id="cb50-495"><a href="#cb50-495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-496"><a href="#cb50-496" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-497"><a href="#cb50-497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-498"><a href="#cb50-498" aria-hidden="true" tabindex="-1"></a>Printing top 50 words across the corpus:</span>
<span id="cb50-499"><a href="#cb50-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-500"><a href="#cb50-500" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_24}</span></span>
<span id="cb50-501"><a href="#cb50-501" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------- START OF CHATGPT CODE ----------------------</span></span>
<span id="cb50-502"><a href="#cb50-502" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> print_top_50_words(corpus, dictionary):</span>
<span id="cb50-503"><a href="#cb50-503" aria-hidden="true" tabindex="-1"></a>    total_word_count <span class="op">=</span> defaultdict(<span class="bu">int</span>)</span>
<span id="cb50-504"><a href="#cb50-504" aria-hidden="true" tabindex="-1"></a>    word_weights <span class="op">=</span> defaultdict(<span class="bu">float</span>)</span>
<span id="cb50-505"><a href="#cb50-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-506"><a href="#cb50-506" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> word_id, word_count <span class="kw">in</span> itertools.chain.from_iterable(corpus):</span>
<span id="cb50-507"><a href="#cb50-507" aria-hidden="true" tabindex="-1"></a>        total_word_count[word_id] <span class="op">+=</span> word_count</span>
<span id="cb50-508"><a href="#cb50-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-509"><a href="#cb50-509" aria-hidden="true" tabindex="-1"></a>    sorted_tota_words_count <span class="op">=</span> <span class="bu">sorted</span>(total_word_count.items(), key <span class="op">=</span> <span class="kw">lambda</span> w: w[<span class="dv">1</span>], reverse <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb50-510"><a href="#cb50-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-511"><a href="#cb50-511" aria-hidden="true" tabindex="-1"></a>    tfidf <span class="op">=</span> TfidfModel(corpus)</span>
<span id="cb50-512"><a href="#cb50-512" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-513"><a href="#cb50-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-514"><a href="#cb50-514" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> doc <span class="kw">in</span> corpus:</span>
<span id="cb50-515"><a href="#cb50-515" aria-hidden="true" tabindex="-1"></a>        tfidf_weights <span class="op">=</span> tfidf[doc]  <span class="co"># Calculate TF-IDF for the review</span></span>
<span id="cb50-516"><a href="#cb50-516" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> term_id, weight <span class="kw">in</span> tfidf_weights:</span>
<span id="cb50-517"><a href="#cb50-517" aria-hidden="true" tabindex="-1"></a>            word_weights[term_id] <span class="op">+=</span> weight  <span class="co"># Aggregate the weight for the term</span></span>
<span id="cb50-518"><a href="#cb50-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-519"><a href="#cb50-519" aria-hidden="true" tabindex="-1"></a>    sorted_word_weights <span class="op">=</span> <span class="bu">sorted</span>(word_weights.items(), key<span class="op">=</span><span class="kw">lambda</span> x: x[<span class="dv">1</span>], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb50-520"><a href="#cb50-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-521"><a href="#cb50-521" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Print the top 50 terms with their weights</span></span>
<span id="cb50-522"><a href="#cb50-522" aria-hidden="true" tabindex="-1"></a>    top_50_words <span class="op">=</span> [(dictionary.get(term_id), weight) <span class="cf">for</span> term_id, weight <span class="kw">in</span> sorted_word_weights[:<span class="dv">50</span>]]</span>
<span id="cb50-523"><a href="#cb50-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-524"><a href="#cb50-524" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> word, weight <span class="kw">in</span> top_50_words:</span>
<span id="cb50-525"><a href="#cb50-525" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(word, weight)</span>
<span id="cb50-526"><a href="#cb50-526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-527"><a href="#cb50-527" aria-hidden="true" tabindex="-1"></a><span class="co"># ---------------------- </span><span class="re">END</span><span class="co"> OF CHATGPT CODE ----------------------</span></span>
<span id="cb50-528"><a href="#cb50-528" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-529"><a href="#cb50-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-530"><a href="#cb50-530" aria-hidden="true" tabindex="-1"></a>Uni-grams over the entire database: </span>
<span id="cb50-531"><a href="#cb50-531" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_25}</span></span>
<span id="cb50-532"><a href="#cb50-532" aria-hidden="true" tabindex="-1"></a>print_top_50_words(database_corpus_unigrams_v1, database_dictionary_unigrams_v1)</span>
<span id="cb50-533"><a href="#cb50-533" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-534"><a href="#cb50-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-535"><a href="#cb50-535" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; use 1710.4405813502553</span></span>
<span id="cb50-536"><a href="#cb50-536" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; </span></span>
<span id="cb50-537"><a href="#cb50-537" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; al 1500.5918177863637</span></span>
<span id="cb50-538"><a href="#cb50-538" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; et 1495.2598944189729</span></span>
<span id="cb50-539"><a href="#cb50-539" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; studi 1254.889113401414</span></span>
<span id="cb50-540"><a href="#cb50-540" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; servic 1177.5025518831014</span></span>
<span id="cb50-541"><a href="#cb50-541" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; research 1155.4801330260996</span></span>
<span id="cb50-542"><a href="#cb50-542" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; model 1093.757883374598</span></span>
<span id="cb50-543"><a href="#cb50-543" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; intent 1085.622080362571</span></span>
<span id="cb50-544"><a href="#cb50-544" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; inform 1035.95718724093</span></span>
<span id="cb50-545"><a href="#cb50-545" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; market 1032.669725701611</span></span>
<span id="cb50-546"><a href="#cb50-546" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; manag 1020.5243612360091</span></span>
<span id="cb50-547"><a href="#cb50-547" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; custom 1011.465319080724</span></span>
<span id="cb50-548"><a href="#cb50-548" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; perceiv 975.0912634817644</span></span>
<span id="cb50-549"><a href="#cb50-549" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; consum 959.7309079460276</span></span>
<span id="cb50-550"><a href="#cb50-550" aria-hidden="true" tabindex="-1"></a><span class="at">and many more </span></span>
<span id="cb50-551"><a href="#cb50-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-552"><a href="#cb50-552" aria-hidden="true" tabindex="-1"></a>Bi-grams over the entire database: </span>
<span id="cb50-553"><a href="#cb50-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-554"><a href="#cb50-554" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_26}</span></span>
<span id="cb50-555"><a href="#cb50-555" aria-hidden="true" tabindex="-1"></a>print_top_50_words(database_corpus_bigrams_v1, database_dictionary_bigrams_v1)</span>
<span id="cb50-556"><a href="#cb50-556" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-557"><a href="#cb50-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-558"><a href="#cb50-558" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; et al 1065.4586868386625</span></span>
<span id="cb50-559"><a href="#cb50-559" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; intern market 424.5870797007975</span></span>
<span id="cb50-560"><a href="#cb50-560" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; inform manag 324.417783324221</span></span>
<span id="cb50-561"><a href="#cb50-561" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; http doiorg 272.8802285987675</span></span>
<span id="cb50-562"><a href="#cb50-562" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; inform system 259.07233958915</span></span>
<span id="cb50-563"><a href="#cb50-563" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; intent use 247.3467671477514</span></span>
<span id="cb50-564"><a href="#cb50-564" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; behavior intent 207.71672202444856</span></span>
<span id="cb50-565"><a href="#cb50-565" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; eas use 206.32538882113823</span></span>
<span id="cb50-566"><a href="#cb50-566" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; comput human 183.94284111390388</span></span>
<span id="cb50-567"><a href="#cb50-567" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; perceiv use 183.0881496709403</span></span>
<span id="cb50-568"><a href="#cb50-568" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; human behavior 179.3628870311971</span></span>
<span id="cb50-569"><a href="#cb50-569" aria-hidden="true" tabindex="-1"></a><span class="at">and many more</span></span>
<span id="cb50-570"><a href="#cb50-570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-571"><a href="#cb50-571" aria-hidden="true" tabindex="-1"></a>Build an LDA model, but I want to test anywhere from 5 to 15 topic numbers, so I'll leave this as a parameter to pass to this function. </span>
<span id="cb50-572"><a href="#cb50-572" aria-hidden="true" tabindex="-1"></a>I left the other parameters as is. </span>
<span id="cb50-573"><a href="#cb50-573" aria-hidden="true" tabindex="-1"></a>You of course need to pass in your corpus (text) and dictionary (you created above).</span>
<span id="cb50-574"><a href="#cb50-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-575"><a href="#cb50-575" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_27}</span></span>
<span id="cb50-576"><a href="#cb50-576" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_lda_model(n_topic, corpus_, dictionary_):</span>
<span id="cb50-577"><a href="#cb50-577" aria-hidden="true" tabindex="-1"></a>    lda_model <span class="op">=</span> gensim.models.ldamodel.LdaModel(corpus <span class="op">=</span> corpus_,</span>
<span id="cb50-578"><a href="#cb50-578" aria-hidden="true" tabindex="-1"></a>                                              num_topics <span class="op">=</span> n_topic,</span>
<span id="cb50-579"><a href="#cb50-579" aria-hidden="true" tabindex="-1"></a>                                              id2word <span class="op">=</span> dictionary_,</span>
<span id="cb50-580"><a href="#cb50-580" aria-hidden="true" tabindex="-1"></a>                                              random_state <span class="op">=</span> <span class="dv">100</span>,</span>
<span id="cb50-581"><a href="#cb50-581" aria-hidden="true" tabindex="-1"></a>                                              update_every <span class="op">=</span> <span class="dv">1</span>,</span>
<span id="cb50-582"><a href="#cb50-582" aria-hidden="true" tabindex="-1"></a>                                              chunksize <span class="op">=</span> <span class="dv">1000</span>,</span>
<span id="cb50-583"><a href="#cb50-583" aria-hidden="true" tabindex="-1"></a>                                              passes <span class="op">=</span> <span class="dv">10</span>,</span>
<span id="cb50-584"><a href="#cb50-584" aria-hidden="true" tabindex="-1"></a>                                              alpha <span class="op">=</span> <span class="st">'auto'</span>,</span>
<span id="cb50-585"><a href="#cb50-585" aria-hidden="true" tabindex="-1"></a>                                              per_word_topics <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb50-586"><a href="#cb50-586" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> lda_model</span>
<span id="cb50-587"><a href="#cb50-587" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-588"><a href="#cb50-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-589"><a href="#cb50-589" aria-hidden="true" tabindex="-1"></a>Here's where I train 11 different models passing in different values for number of topics. </span>
<span id="cb50-590"><a href="#cb50-590" aria-hidden="true" tabindex="-1"></a>I save each model in a list. </span>
<span id="cb50-591"><a href="#cb50-591" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_28}</span></span>
<span id="cb50-592"><a href="#cb50-592" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_models(corpus_, dictionary_):</span>
<span id="cb50-593"><a href="#cb50-593" aria-hidden="true" tabindex="-1"></a>    list_to_hold_models <span class="op">=</span> []</span>
<span id="cb50-594"><a href="#cb50-594" aria-hidden="true" tabindex="-1"></a>    topic_n_to_try <span class="op">=</span> [<span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">11</span>, <span class="dv">12</span>, <span class="dv">13</span>, <span class="dv">14</span>, <span class="dv">15</span>]</span>
<span id="cb50-595"><a href="#cb50-595" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb50-596"><a href="#cb50-596" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(topic_n_to_try)):</span>
<span id="cb50-597"><a href="#cb50-597" aria-hidden="true" tabindex="-1"></a>        list_to_hold_models.insert(i, build_lda_model(topic_n_to_try[i], corpus_, dictionary_))</span>
<span id="cb50-598"><a href="#cb50-598" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb50-599"><a href="#cb50-599" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> list_to_hold_models</span>
<span id="cb50-600"><a href="#cb50-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-601"><a href="#cb50-601" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-602"><a href="#cb50-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-603"><a href="#cb50-603" aria-hidden="true" tabindex="-1"></a>You can calculate both perplexity and coherence. </span>
<span id="cb50-604"><a href="#cb50-604" aria-hidden="true" tabindex="-1"></a>Coherence is more straightforward: It's a measure of how correct your model is. </span>
<span id="cb50-605"><a href="#cb50-605" aria-hidden="true" tabindex="-1"></a>Perplexity, not that difficult, it's how off you are. </span>
<span id="cb50-606"><a href="#cb50-606" aria-hidden="true" tabindex="-1"></a>So, you want higher coherence, and lower perplexity. </span>
<span id="cb50-607"><a href="#cb50-607" aria-hidden="true" tabindex="-1"></a>It's easier to just focus on one of them. </span>
<span id="cb50-608"><a href="#cb50-608" aria-hidden="true" tabindex="-1"></a>But for practice, I did both! </span>
<span id="cb50-609"><a href="#cb50-609" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_29}</span></span>
<span id="cb50-610"><a href="#cb50-610" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_perplexity(model, corpus_):</span>
<span id="cb50-611"><a href="#cb50-611" aria-hidden="true" tabindex="-1"></a>    perplexity <span class="op">=</span> model.log_perplexity(corpus_)</span>
<span id="cb50-612"><a href="#cb50-612" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> perplexity</span>
<span id="cb50-613"><a href="#cb50-613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-614"><a href="#cb50-614" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_coherence(model, text, dictionary_):</span>
<span id="cb50-615"><a href="#cb50-615" aria-hidden="true" tabindex="-1"></a>    coherence_model_lda <span class="op">=</span> CoherenceModel(model <span class="op">=</span> model, texts <span class="op">=</span> text, dictionary <span class="op">=</span> dictionary_, coherence<span class="op">=</span><span class="st">'c_v'</span>)</span>
<span id="cb50-616"><a href="#cb50-616" aria-hidden="true" tabindex="-1"></a>    coherence_lda <span class="op">=</span> coherence_model_lda.get_coherence()</span>
<span id="cb50-617"><a href="#cb50-617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-618"><a href="#cb50-618" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> coherence_lda</span>
<span id="cb50-619"><a href="#cb50-619" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-620"><a href="#cb50-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-621"><a href="#cb50-621" aria-hidden="true" tabindex="-1"></a>Here's how to compare models: build a table with columns <span class="in">`Num_Topics`</span> and values of Coherence and Perplexity for each model. </span>
<span id="cb50-622"><a href="#cb50-622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-623"><a href="#cb50-623" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_30}</span></span>
<span id="cb50-624"><a href="#cb50-624" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> build_model_comparison_table(list_of_models, corpus_, dictionary_, data):</span>
<span id="cb50-625"><a href="#cb50-625" aria-hidden="true" tabindex="-1"></a>    tracker <span class="op">=</span> <span class="dv">5</span> </span>
<span id="cb50-626"><a href="#cb50-626" aria-hidden="true" tabindex="-1"></a>    models_perplexity <span class="op">=</span> []</span>
<span id="cb50-627"><a href="#cb50-627" aria-hidden="true" tabindex="-1"></a>    models_coherence <span class="op">=</span> []</span>
<span id="cb50-628"><a href="#cb50-628" aria-hidden="true" tabindex="-1"></a>    models_topics <span class="op">=</span> [<span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">10</span>, <span class="dv">11</span>, <span class="dv">12</span>, <span class="dv">13</span>, <span class="dv">14</span>, <span class="dv">15</span>]</span>
<span id="cb50-629"><a href="#cb50-629" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb50-630"><a href="#cb50-630" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb50-631"><a href="#cb50-631" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> model <span class="kw">in</span> list_of_models:</span>
<span id="cb50-632"><a href="#cb50-632" aria-hidden="true" tabindex="-1"></a>        models_perplexity.append(calculate_perplexity(model, corpus_))</span>
<span id="cb50-633"><a href="#cb50-633" aria-hidden="true" tabindex="-1"></a>        models_coherence.append(calculate_coherence(model, data, dictionary_))</span>
<span id="cb50-634"><a href="#cb50-634" aria-hidden="true" tabindex="-1"></a>        tracker <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb50-635"><a href="#cb50-635" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb50-636"><a href="#cb50-636" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> tracker <span class="op">==</span> <span class="dv">10</span>:</span>
<span id="cb50-637"><a href="#cb50-637" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Successfully generated model comparison table."</span>) </span>
<span id="cb50-638"><a href="#cb50-638" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb50-639"><a href="#cb50-639" aria-hidden="true" tabindex="-1"></a>    models_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb50-640"><a href="#cb50-640" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Num_Topics'</span>: models_topics,</span>
<span id="cb50-641"><a href="#cb50-641" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Coherence'</span>: models_coherence,</span>
<span id="cb50-642"><a href="#cb50-642" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Perplexity'</span>: models_perplexity,</span>
<span id="cb50-643"><a href="#cb50-643" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb50-644"><a href="#cb50-644" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-645"><a href="#cb50-645" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> models_df</span>
<span id="cb50-646"><a href="#cb50-646" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-647"><a href="#cb50-647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-648"><a href="#cb50-648" aria-hidden="true" tabindex="-1"></a>You can either look at the values, or have this code find you the best. </span>
<span id="cb50-649"><a href="#cb50-649" aria-hidden="true" tabindex="-1"></a>Here, I pick the maximum coherence and minimum perplexity. </span>
<span id="cb50-650"><a href="#cb50-650" aria-hidden="true" tabindex="-1"></a>But, what if it's two difference values? </span>
<span id="cb50-651"><a href="#cb50-651" aria-hidden="true" tabindex="-1"></a>As in, for example, topic number 5 gives the highest coherence but also the highest perplexity, and topic number 10 gives the lowest perplexity but lower coherence. </span>
<span id="cb50-652"><a href="#cb50-652" aria-hidden="true" tabindex="-1"></a>Which do you choose? </span>
<span id="cb50-653"><a href="#cb50-653" aria-hidden="true" tabindex="-1"></a>Well, I decided they're both equally as important, so I come up with a score for each topic number that's just the weighted average of coherence and perplexity. </span>
<span id="cb50-654"><a href="#cb50-654" aria-hidden="true" tabindex="-1"></a>Or, save yourself the headache and just use one metric. </span>
<span id="cb50-655"><a href="#cb50-655" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_31}</span></span>
<span id="cb50-656"><a href="#cb50-656" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> find_best_model(models_df):</span>
<span id="cb50-657"><a href="#cb50-657" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Number of topics with the maximum Coherence is "</span>, models_df.loc[models_df[<span class="st">'Coherence'</span>].idxmax(), <span class="st">'Num_Topics'</span>])</span>
<span id="cb50-658"><a href="#cb50-658" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Number of topics with the minimum Perplexity is "</span>, models_df.loc[models_df[<span class="st">'Perplexity'</span>].idxmin(), <span class="st">'Num_Topics'</span>])</span>
<span id="cb50-659"><a href="#cb50-659" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb50-660"><a href="#cb50-660" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> models_df.loc[models_df[<span class="st">'Coherence'</span>].idxmax(), <span class="st">'Num_Topics'</span>] <span class="op">==</span> models_df.loc[models_df[<span class="st">'Perplexity'</span>].idxmin(), <span class="st">'Num_Topics'</span>]:</span>
<span id="cb50-661"><a href="#cb50-661" aria-hidden="true" tabindex="-1"></a>        best_model_row <span class="op">=</span> models_df.loc[models_df[<span class="st">'Perplexity'</span>].idxmin()]</span>
<span id="cb50-662"><a href="#cb50-662" aria-hidden="true" tabindex="-1"></a>        best_number_of_topics <span class="op">=</span> best_model_row[<span class="st">'Num_Topics'</span>]</span>
<span id="cb50-663"><a href="#cb50-663" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb50-664"><a href="#cb50-664" aria-hidden="true" tabindex="-1"></a>        models_df[<span class="st">'Normalized_Perplexity'</span>] <span class="op">=</span> (models_df[<span class="st">'Perplexity'</span>] <span class="op">-</span> models_df[<span class="st">'Perplexity'</span>].<span class="bu">min</span>()) <span class="op">/</span> (models_df[<span class="st">'Perplexity'</span>].<span class="bu">max</span>() <span class="op">-</span> models_df[<span class="st">'Perplexity'</span>].<span class="bu">min</span>())</span>
<span id="cb50-665"><a href="#cb50-665" aria-hidden="true" tabindex="-1"></a>        models_df[<span class="st">'Normalized_Coherence'</span>] <span class="op">=</span> (models_df[<span class="st">'Coherence'</span>] <span class="op">-</span> models_df[<span class="st">'Coherence'</span>].<span class="bu">min</span>()) <span class="op">/</span> (models_df[<span class="st">'Coherence'</span>].<span class="bu">max</span>() <span class="op">-</span> models_df[<span class="st">'Coherence'</span>].<span class="bu">min</span>())</span>
<span id="cb50-666"><a href="#cb50-666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-667"><a href="#cb50-667" aria-hidden="true" tabindex="-1"></a>        models_df[<span class="st">'Inverted_Perplexity'</span>] <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> models_df[<span class="st">'Normalized_Perplexity'</span>] <span class="co"># because smaller is better</span></span>
<span id="cb50-668"><a href="#cb50-668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-669"><a href="#cb50-669" aria-hidden="true" tabindex="-1"></a>        weight_preplexity <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb50-670"><a href="#cb50-670" aria-hidden="true" tabindex="-1"></a>        weight_coherence <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb50-671"><a href="#cb50-671" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-672"><a href="#cb50-672" aria-hidden="true" tabindex="-1"></a>        models_df[<span class="st">'Score'</span>] <span class="op">=</span> weight_coherence <span class="op">*</span> models_df[<span class="st">'Normalized_Coherence'</span>] <span class="op">+</span> weight_preplexity <span class="op">*</span> models_df[<span class="st">'Inverted_Perplexity'</span>]</span>
<span id="cb50-673"><a href="#cb50-673" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-674"><a href="#cb50-674" aria-hidden="true" tabindex="-1"></a>        best_model_row <span class="op">=</span> models_df.loc[models_df[<span class="st">'Score'</span>].idxmax()]</span>
<span id="cb50-675"><a href="#cb50-675" aria-hidden="true" tabindex="-1"></a>        best_number_of_topics <span class="op">=</span> best_model_row[<span class="st">'Num_Topics'</span>]</span>
<span id="cb50-676"><a href="#cb50-676" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-677"><a href="#cb50-677" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(best_model_row)</span>
<span id="cb50-678"><a href="#cb50-678" aria-hidden="true" tabindex="-1"></a>                                       </span>
<span id="cb50-679"><a href="#cb50-679" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_model_row, best_number_of_topics</span>
<span id="cb50-680"><a href="#cb50-680" aria-hidden="true" tabindex="-1"></a>                                                                                                     </span>
<span id="cb50-681"><a href="#cb50-681" aria-hidden="true" tabindex="-1"></a>                                                                                                </span>
<span id="cb50-682"><a href="#cb50-682" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> pick_best_model(num, m):</span>
<span id="cb50-683"><a href="#cb50-683" aria-hidden="true" tabindex="-1"></a>    <span class="co">""" </span></span>
<span id="cb50-684"><a href="#cb50-684" aria-hidden="true" tabindex="-1"></a><span class="co">    Model inputs are: </span></span>
<span id="cb50-685"><a href="#cb50-685" aria-hidden="true" tabindex="-1"></a><span class="co">        num = best number of topics found according to find_best_model()</span></span>
<span id="cb50-686"><a href="#cb50-686" aria-hidden="true" tabindex="-1"></a><span class="co">        m = list of models </span></span>
<span id="cb50-687"><a href="#cb50-687" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb50-688"><a href="#cb50-688" aria-hidden="true" tabindex="-1"></a>    model_index <span class="op">=</span> num <span class="op">-</span> <span class="dv">5</span> </span>
<span id="cb50-689"><a href="#cb50-689" aria-hidden="true" tabindex="-1"></a>    model_index <span class="op">=</span> <span class="bu">int</span>(model_index)</span>
<span id="cb50-690"><a href="#cb50-690" aria-hidden="true" tabindex="-1"></a>                                       </span>
<span id="cb50-691"><a href="#cb50-691" aria-hidden="true" tabindex="-1"></a>    best_model <span class="op">=</span> m[model_index]</span>
<span id="cb50-692"><a href="#cb50-692" aria-hidden="true" tabindex="-1"></a>                                       </span>
<span id="cb50-693"><a href="#cb50-693" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> best_model  </span>
<span id="cb50-694"><a href="#cb50-694" aria-hidden="true" tabindex="-1"></a>                                                                  </span>
<span id="cb50-695"><a href="#cb50-695" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> print_topics(model, corpus):</span>
<span id="cb50-696"><a href="#cb50-696" aria-hidden="true" tabindex="-1"></a>    pprint(model.print_topics())</span>
<span id="cb50-697"><a href="#cb50-697" aria-hidden="true" tabindex="-1"></a>    doc_lda <span class="op">=</span> model[corpus]</span>
<span id="cb50-698"><a href="#cb50-698" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb50-699"><a href="#cb50-699" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> doc_lda</span>
<span id="cb50-700"><a href="#cb50-700" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-701"><a href="#cb50-701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-702"><a href="#cb50-702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-703"><a href="#cb50-703" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Topic Modeling - Unigrams </span></span>
<span id="cb50-704"><a href="#cb50-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-705"><a href="#cb50-705" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-706"><a href="#cb50-706" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_32}</span></span>
<span id="cb50-707"><a href="#cb50-707" aria-hidden="true" tabindex="-1"></a>unigram_models_v1 <span class="op">=</span> train_models(database_corpus_unigrams_v1, database_dictionary_unigrams_v1)</span>
<span id="cb50-708"><a href="#cb50-708" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-709"><a href="#cb50-709" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-710"><a href="#cb50-710" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-711"><a href="#cb50-711" aria-hidden="true" tabindex="-1"></a>Here are the results for unigram models: </span>
<span id="cb50-712"><a href="#cb50-712" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_33}</span></span>
<span id="cb50-713"><a href="#cb50-713" aria-hidden="true" tabindex="-1"></a>unigram_model_comparison_v1 <span class="op">=</span> build_model_comparison_table(unigram_models_v1, database_corpus_unigrams_v1, database_dictionary_unigrams_v1, entire_database_listoflists_unigrams_v1)</span>
<span id="cb50-714"><a href="#cb50-714" aria-hidden="true" tabindex="-1"></a>unigram_model_comparison_v1</span>
<span id="cb50-715"><a href="#cb50-715" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-716"><a href="#cb50-716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-717"><a href="#cb50-717" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>Num_Topics<span class="pp">|</span>Coherence<span class="pp">|</span>  Perplexity<span class="pp">|</span></span>
<span id="cb50-718"><a href="#cb50-718" aria-hidden="true" tabindex="-1"></a><span class="pp">|----------|---------|------------|</span></span>
<span id="cb50-719"><a href="#cb50-719" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>0  <span class="pp">|</span> 5  <span class="pp">|</span> 0.436565<span class="pp">|</span>    -7.706499<span class="pp">|</span></span>
<span id="cb50-720"><a href="#cb50-720" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>1  <span class="pp">|</span> 6  <span class="pp">|</span> 0.413618<span class="pp">|</span>    -7.754855<span class="pp">|</span></span>
<span id="cb50-721"><a href="#cb50-721" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>2  <span class="pp">|</span> 7  <span class="pp">|</span> 0.469700<span class="pp">|</span>    -7.810709<span class="pp">|</span></span>
<span id="cb50-722"><a href="#cb50-722" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>3  <span class="pp">|</span> 8  <span class="pp">|</span> 0.400105<span class="pp">|</span>    -7.900533<span class="pp">|</span></span>
<span id="cb50-723"><a href="#cb50-723" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>4  <span class="pp">|</span> 9  <span class="pp">|</span> 0.452116<span class="pp">|</span>    -8.012850<span class="pp">|</span></span>
<span id="cb50-724"><a href="#cb50-724" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>5  <span class="pp">|</span> 10 <span class="pp">|</span>  0.420971<span class="pp">|</span>   -8.215140<span class="pp">|</span></span>
<span id="cb50-725"><a href="#cb50-725" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>6  <span class="pp">|</span> 11 <span class="pp">|</span>  0.446276<span class="pp">|</span>   -8.535079<span class="pp">|</span></span>
<span id="cb50-726"><a href="#cb50-726" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>7  <span class="pp">|</span> 12 <span class="pp">|</span>  0.454530<span class="pp">|</span>   -9.011387<span class="pp">|</span></span>
<span id="cb50-727"><a href="#cb50-727" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>8  <span class="pp">|</span> 13 <span class="pp">|</span>  0.409933<span class="pp">|</span>   -9.724786<span class="pp">|</span></span>
<span id="cb50-728"><a href="#cb50-728" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>9  <span class="pp">|</span> 14 <span class="pp">|</span>  0.418211<span class="pp">|</span>   -10.555475<span class="pp">|</span></span>
<span id="cb50-729"><a href="#cb50-729" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>10 <span class="pp">|</span> 15 <span class="pp">|</span>  0.406770<span class="pp">|</span>   -11.291644<span class="pp">|</span></span>
<span id="cb50-730"><a href="#cb50-730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-731"><a href="#cb50-731" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-732"><a href="#cb50-732" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_34}</span></span>
<span id="cb50-733"><a href="#cb50-733" aria-hidden="true" tabindex="-1"></a>unigram_best_row_v1 <span class="op">=</span> find_best_model(unigram_model_comparison_v1)[<span class="dv">0</span>]</span>
<span id="cb50-734"><a href="#cb50-734" aria-hidden="true" tabindex="-1"></a>unigram_best_n_topics_v1 <span class="op">=</span> find_best_model(unigram_model_comparison_v1)[<span class="dv">1</span>]</span>
<span id="cb50-735"><a href="#cb50-735" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-736"><a href="#cb50-736" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-737"><a href="#cb50-737" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Number of topics with the maximum Coherence is  7</span></span>
<span id="cb50-738"><a href="#cb50-738" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Number of topics with the minimum Perplexity is  15</span></span>
<span id="cb50-739"><a href="#cb50-739" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Num_Topics               12.000000</span></span>
<span id="cb50-740"><a href="#cb50-740" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Coherence                 0.454530</span></span>
<span id="cb50-741"><a href="#cb50-741" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Perplexity               -9.011387</span></span>
<span id="cb50-742"><a href="#cb50-742" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Normalized_Perplexity     0.636029</span></span>
<span id="cb50-743"><a href="#cb50-743" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Normalized_Coherence      0.782020</span></span>
<span id="cb50-744"><a href="#cb50-744" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Inverted_Perplexity       0.363971</span></span>
<span id="cb50-745"><a href="#cb50-745" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Score                     0.572996</span></span>
<span id="cb50-746"><a href="#cb50-746" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Name: 7, dtype: float64</span></span>
<span id="cb50-747"><a href="#cb50-747" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Number of topics with the maximum Coherence is  7</span></span>
<span id="cb50-748"><a href="#cb50-748" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Number of topics with the minimum Perplexity is  15</span></span>
<span id="cb50-749"><a href="#cb50-749" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Num_Topics               12.000000</span></span>
<span id="cb50-750"><a href="#cb50-750" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Coherence                 0.454530</span></span>
<span id="cb50-751"><a href="#cb50-751" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Perplexity               -9.011387</span></span>
<span id="cb50-752"><a href="#cb50-752" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Normalized_Perplexity     0.636029</span></span>
<span id="cb50-753"><a href="#cb50-753" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Normalized_Coherence      0.782020</span></span>
<span id="cb50-754"><a href="#cb50-754" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Inverted_Perplexity       0.363971</span></span>
<span id="cb50-755"><a href="#cb50-755" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Score                     0.572996</span></span>
<span id="cb50-756"><a href="#cb50-756" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Name: 7, dtype: float64</span></span>
<span id="cb50-757"><a href="#cb50-757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-758"><a href="#cb50-758" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-759"><a href="#cb50-759" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_35}</span></span>
<span id="cb50-760"><a href="#cb50-760" aria-hidden="true" tabindex="-1"></a>unigram_best_model_v1 <span class="op">=</span> pick_best_model(unigram_best_n_topics_v1, unigram_models_v1)</span>
<span id="cb50-761"><a href="#cb50-761" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best Unigram model is (V1):"</span>, unigram_best_model_v1)</span>
<span id="cb50-762"><a href="#cb50-762" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-763"><a href="#cb50-763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-764"><a href="#cb50-764" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Best Unigram model is (V1): LdaModel(num_terms=27200, num_topics=12, decay=0.5, chunksize=1000)</span></span>
<span id="cb50-765"><a href="#cb50-765" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-766"><a href="#cb50-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-767"><a href="#cb50-767" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-768"><a href="#cb50-768" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Topic Modeling - Bigrams </span></span>
<span id="cb50-769"><a href="#cb50-769" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-770"><a href="#cb50-770" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_36}</span></span>
<span id="cb50-771"><a href="#cb50-771" aria-hidden="true" tabindex="-1"></a>bigram_models_v1 <span class="op">=</span> train_models(database_corpus_bigrams_v1, database_dictionary_bigrams_v1)</span>
<span id="cb50-772"><a href="#cb50-772" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-773"><a href="#cb50-773" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-774"><a href="#cb50-774" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-775"><a href="#cb50-775" aria-hidden="true" tabindex="-1"></a>And the bigrams: </span>
<span id="cb50-776"><a href="#cb50-776" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_37}</span></span>
<span id="cb50-777"><a href="#cb50-777" aria-hidden="true" tabindex="-1"></a>bigram_model_comparison_v1 <span class="op">=</span> build_model_comparison_table(bigram_models_v1, database_corpus_bigrams_v1, database_dictionary_bigrams_v1, entire_database_listoflists_bigrams_v1)</span>
<span id="cb50-778"><a href="#cb50-778" aria-hidden="true" tabindex="-1"></a>bigram_model_comparison_v1</span>
<span id="cb50-779"><a href="#cb50-779" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-780"><a href="#cb50-780" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-781"><a href="#cb50-781" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>Num_Topics<span class="pp">|</span>Coherence<span class="pp">|</span>  Perplexity<span class="pp">|</span></span>
<span id="cb50-782"><a href="#cb50-782" aria-hidden="true" tabindex="-1"></a><span class="pp">|----------|---------|------------|</span></span>
<span id="cb50-783"><a href="#cb50-783" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>0  <span class="pp">|</span>5<span class="pp">|</span> 0.558434<span class="pp">|</span>   -13.502056<span class="pp">|</span></span>
<span id="cb50-784"><a href="#cb50-784" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>1  <span class="pp">|</span>6<span class="pp">|</span> 0.535400<span class="pp">|</span>   -13.983511<span class="pp">|</span></span>
<span id="cb50-785"><a href="#cb50-785" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>2  <span class="pp">|</span>7<span class="pp">|</span> 0.542287<span class="pp">|</span>   -14.569705<span class="pp">|</span></span>
<span id="cb50-786"><a href="#cb50-786" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>3  <span class="pp">|</span>8<span class="pp">|</span> 0.515335<span class="pp">|</span>   -15.336498<span class="pp">|</span></span>
<span id="cb50-787"><a href="#cb50-787" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>4  <span class="pp">|</span>9<span class="pp">|</span> 0.523767<span class="pp">|</span>   -16.263962<span class="pp">|</span></span>
<span id="cb50-788"><a href="#cb50-788" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>5  <span class="pp">|</span>10<span class="pp">|</span>    0.526290<span class="pp">|</span>   -17.388975<span class="pp">|</span></span>
<span id="cb50-789"><a href="#cb50-789" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>6  <span class="pp">|</span>11<span class="pp">|</span>    0.523879<span class="pp">|</span>   -18.634021<span class="pp">|</span></span>
<span id="cb50-790"><a href="#cb50-790" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>7  <span class="pp">|</span>12<span class="pp">|</span>    0.513803<span class="pp">|</span>   -20.200456<span class="pp">|</span></span>
<span id="cb50-791"><a href="#cb50-791" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>8  <span class="pp">|</span>13<span class="pp">|</span>    0.510867<span class="pp">|</span>   -21.721155<span class="pp">|</span></span>
<span id="cb50-792"><a href="#cb50-792" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>9  <span class="pp">|</span>14<span class="pp">|</span>    0.554809<span class="pp">|</span>   -23.230322<span class="pp">|</span></span>
<span id="cb50-793"><a href="#cb50-793" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>10 <span class="pp">|</span>15<span class="pp">|</span>    0.582336<span class="pp">|</span>   -24.581214<span class="pp">|</span></span>
<span id="cb50-794"><a href="#cb50-794" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-795"><a href="#cb50-795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-796"><a href="#cb50-796" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_38}</span></span>
<span id="cb50-797"><a href="#cb50-797" aria-hidden="true" tabindex="-1"></a>bigram_best_row_v1 <span class="op">=</span> find_best_model(bigram_model_comparison_v1)[<span class="dv">0</span>]</span>
<span id="cb50-798"><a href="#cb50-798" aria-hidden="true" tabindex="-1"></a>bigram_best_n_topics_v1 <span class="op">=</span> find_best_model(bigram_model_comparison_v1)[<span class="dv">1</span>]</span>
<span id="cb50-799"><a href="#cb50-799" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-800"><a href="#cb50-800" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-801"><a href="#cb50-801" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Number of topics with the maximum Coherence is  15</span></span>
<span id="cb50-802"><a href="#cb50-802" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Number of topics with the minimum Perplexity is  15</span></span>
<span id="cb50-803"><a href="#cb50-803" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Num_Topics    15.000000</span></span>
<span id="cb50-804"><a href="#cb50-804" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Coherence      0.582336</span></span>
<span id="cb50-805"><a href="#cb50-805" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Perplexity   -24.581214</span></span>
<span id="cb50-806"><a href="#cb50-806" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Name: 10, dtype: float64</span></span>
<span id="cb50-807"><a href="#cb50-807" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Number of topics with the maximum Coherence is  15</span></span>
<span id="cb50-808"><a href="#cb50-808" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Number of topics with the minimum Perplexity is  15</span></span>
<span id="cb50-809"><a href="#cb50-809" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Num_Topics    15.000000</span></span>
<span id="cb50-810"><a href="#cb50-810" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Coherence      0.582336</span></span>
<span id="cb50-811"><a href="#cb50-811" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Perplexity   -24.581214</span></span>
<span id="cb50-812"><a href="#cb50-812" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Name: 10, dtype: float64</span></span>
<span id="cb50-813"><a href="#cb50-813" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-814"><a href="#cb50-814" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_39}</span></span>
<span id="cb50-815"><a href="#cb50-815" aria-hidden="true" tabindex="-1"></a>bigram_best_model_v1 <span class="op">=</span> pick_best_model(bigram_best_n_topics_v1, bigram_models_v1)</span>
<span id="cb50-816"><a href="#cb50-816" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best Unigram model is (V1):"</span>, bigram_best_model_v1)</span>
<span id="cb50-817"><a href="#cb50-817" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-818"><a href="#cb50-818" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-819"><a href="#cb50-819" aria-hidden="true" tabindex="-1"></a><span class="at">&gt; Best Unigram model is (V1): LdaModel(num_terms=306163, num_topics=15, decay=0.5, chunksize=1000)</span></span>
<span id="cb50-820"><a href="#cb50-820" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-821"><a href="#cb50-821" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-822"><a href="#cb50-822" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Pick Best Model </span></span>
<span id="cb50-823"><a href="#cb50-823" aria-hidden="true" tabindex="-1"></a>This is different from my dissertation because I actually didn't upload all the pdf's here, and also I'm looking at both scores where I only looked at Coherence.</span>
<span id="cb50-824"><a href="#cb50-824" aria-hidden="true" tabindex="-1"></a>Also, 15 topics is way too many. </span>
<span id="cb50-825"><a href="#cb50-825" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_40}</span></span>
<span id="cb50-826"><a href="#cb50-826" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> model_score(p, c, wp <span class="op">=</span> <span class="fl">0.5</span>, wc <span class="op">=</span> <span class="fl">0.5</span>):</span>
<span id="cb50-827"><a href="#cb50-827" aria-hidden="true" tabindex="-1"></a>    <span class="co">""" Calculates model score with 0.5 weights as default"""</span></span>
<span id="cb50-828"><a href="#cb50-828" aria-hidden="true" tabindex="-1"></a>    score <span class="op">=</span> (<span class="dv">1</span> <span class="op">-</span> p) <span class="op">*</span> wp <span class="op">+</span> c <span class="op">*</span> wc </span>
<span id="cb50-829"><a href="#cb50-829" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> score</span>
<span id="cb50-830"><a href="#cb50-830" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-831"><a href="#cb50-831" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-832"><a href="#cb50-832" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_41}</span></span>
<span id="cb50-833"><a href="#cb50-833" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best unigram model's score is (V1):"</span>, model_score(<span class="op">-</span><span class="fl">9.011387</span>,<span class="fl">0.454530</span>))</span>
<span id="cb50-834"><a href="#cb50-834" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best bigram model's score is (V1):"</span>, model_score(<span class="op">-</span><span class="fl">24.581214</span>,<span class="fl">0.582336</span>))</span>
<span id="cb50-835"><a href="#cb50-835" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-836"><a href="#cb50-836" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-837"><a href="#cb50-837" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>NGRAM<span class="pp">|</span>Perplexity<span class="pp">|</span>Coherence<span class="pp">|</span># of topics<span class="pp">|</span>Score<span class="pp">|</span></span>
<span id="cb50-838"><a href="#cb50-838" aria-hidden="true" tabindex="-1"></a><span class="pp">|-----|----------|---------|-----------|-----|</span></span>
<span id="cb50-839"><a href="#cb50-839" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>UNI<span class="pp">|</span>$-9.011387$<span class="pp">|</span>$0.454530$<span class="pp">|</span>$12$<span class="pp">|</span>$5.2329585$<span class="pp">|</span></span>
<span id="cb50-840"><a href="#cb50-840" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>BI<span class="pp">|</span>$-24.581214$<span class="pp">|</span>$0.582336$<span class="pp">|</span>$15$<span class="pp">|</span>$13.081775$<span class="pp">|</span></span>
<span id="cb50-841"><a href="#cb50-841" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-842"><a href="#cb50-842" aria-hidden="true" tabindex="-1"></a>The best model overall is therefore <span class="in">`bigram_best_model`</span>. </span>
<span id="cb50-843"><a href="#cb50-843" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-844"><a href="#cb50-844" aria-hidden="true" tabindex="-1"></a>I chose bigrams, but went with 8-9 topics. </span>
<span id="cb50-845"><a href="#cb50-845" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_42}</span></span>
<span id="cb50-846"><a href="#cb50-846" aria-hidden="true" tabindex="-1"></a>best_topic_model_v1 <span class="op">=</span> bigram_best_model_v1</span>
<span id="cb50-847"><a href="#cb50-847" aria-hidden="true" tabindex="-1"></a>number_of_topics <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb50-848"><a href="#cb50-848" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-849"><a href="#cb50-849" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-850"><a href="#cb50-850" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-851"><a href="#cb50-851" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_43}</span></span>
<span id="cb50-852"><a href="#cb50-852" aria-hidden="true" tabindex="-1"></a>print_topics(best_topic_model_v1, database_corpus_bigrams_v1)</span>
<span id="cb50-853"><a href="#cb50-853" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-854"><a href="#cb50-854" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-855"><a href="#cb50-855" aria-hidden="true" tabindex="-1"></a><span class="al">![](/images/topics_table.png)</span></span>
<span id="cb50-856"><a href="#cb50-856" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-857"><a href="#cb50-857" aria-hidden="true" tabindex="-1"></a><span class="fu">### Topic Modeling using Keywords </span></span>
<span id="cb50-858"><a href="#cb50-858" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-859"><a href="#cb50-859" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-860"><a href="#cb50-860" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_44}</span></span>
<span id="cb50-861"><a href="#cb50-861" aria-hidden="true" tabindex="-1"></a>keywordsDf <span class="op">=</span> df.loc[:,<span class="st">'K1'</span>:<span class="st">'K10'</span>]</span>
<span id="cb50-862"><a href="#cb50-862" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-863"><a href="#cb50-863" aria-hidden="true" tabindex="-1"></a>keywords_across_db <span class="op">=</span> keywordsDf.values.flatten().tolist()</span>
<span id="cb50-864"><a href="#cb50-864" aria-hidden="true" tabindex="-1"></a><span class="bu">len</span>(keywords_across_db)</span>
<span id="cb50-865"><a href="#cb50-865" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-866"><a href="#cb50-866" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-867"><a href="#cb50-867" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-868"><a href="#cb50-868" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-869"><a href="#cb50-869" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_45}</span></span>
<span id="cb50-870"><a href="#cb50-870" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb50-871"><a href="#cb50-871" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-872"><a href="#cb50-872" aria-hidden="true" tabindex="-1"></a>empty_or_na_count <span class="op">=</span> <span class="bu">sum</span>(<span class="dv">1</span> <span class="cf">for</span> x <span class="kw">in</span> keywords_across_db <span class="cf">if</span> x <span class="kw">in</span> [<span class="va">None</span>, <span class="st">""</span>, <span class="st">' '</span>] <span class="kw">or</span> (<span class="bu">isinstance</span>(x, <span class="bu">float</span>) <span class="kw">and</span> math.isnan(x)))</span>
<span id="cb50-873"><a href="#cb50-873" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-874"><a href="#cb50-874" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Number of empty or NA values: </span><span class="sc">{</span>empty_or_na_count<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb50-875"><a href="#cb50-875" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-876"><a href="#cb50-876" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-877"><a href="#cb50-877" aria-hidden="true" tabindex="-1"></a>keywords_across_db <span class="op">=</span> [x <span class="cf">for</span> x <span class="kw">in</span> keywords_across_db <span class="cf">if</span> x <span class="kw">not</span> <span class="kw">in</span> [<span class="va">None</span>, <span class="st">""</span>, <span class="st">' '</span>] <span class="kw">and</span> <span class="kw">not</span> (<span class="bu">isinstance</span>(x, <span class="bu">float</span>) <span class="kw">and</span> math.isnan(x))]</span>
<span id="cb50-878"><a href="#cb50-878" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-879"><a href="#cb50-879" aria-hidden="true" tabindex="-1"></a>keywords_across_db_nodup <span class="op">=</span> <span class="bu">list</span>(<span class="bu">set</span>(keywords_across_db))</span>
<span id="cb50-880"><a href="#cb50-880" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-881"><a href="#cb50-881" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-882"><a href="#cb50-882" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-883"><a href="#cb50-883" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_46}</span></span>
<span id="cb50-884"><a href="#cb50-884" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> BertTokenizer, BertModel</span>
<span id="cb50-885"><a href="#cb50-885" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-886"><a href="#cb50-886" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> BertTokenizer.from_pretrained(<span class="st">'bert-base-uncased'</span>)</span>
<span id="cb50-887"><a href="#cb50-887" aria-hidden="true" tabindex="-1"></a>model_bert <span class="op">=</span> BertModel.from_pretrained(<span class="st">'bert-base-uncased'</span>)</span>
<span id="cb50-888"><a href="#cb50-888" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-889"><a href="#cb50-889" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_embedding(text):</span>
<span id="cb50-890"><a href="#cb50-890" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> tokenizer(text, return_tensors<span class="op">=</span><span class="st">'pt'</span>, truncation<span class="op">=</span><span class="va">True</span>, padding<span class="op">=</span><span class="va">True</span>, max_length<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb50-891"><a href="#cb50-891" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb50-892"><a href="#cb50-892" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model_bert(<span class="op">**</span>inputs)</span>
<span id="cb50-893"><a href="#cb50-893" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> outputs.last_hidden_state.mean(dim<span class="op">=</span><span class="dv">1</span>).squeeze().numpy()</span>
<span id="cb50-894"><a href="#cb50-894" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-895"><a href="#cb50-895" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-896"><a href="#cb50-896" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-897"><a href="#cb50-897" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-898"><a href="#cb50-898" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_47}</span></span>
<span id="cb50-899"><a href="#cb50-899" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> print_clusters(n_clusters, list_of_words):</span>
<span id="cb50-900"><a href="#cb50-900" aria-hidden="true" tabindex="-1"></a>    clusters <span class="op">=</span> {i: [] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_clusters)}</span>
<span id="cb50-901"><a href="#cb50-901" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> word, label <span class="kw">in</span> <span class="bu">zip</span>(list_of_words, labels):</span>
<span id="cb50-902"><a href="#cb50-902" aria-hidden="true" tabindex="-1"></a>        clusters[label].append(word)</span>
<span id="cb50-903"><a href="#cb50-903" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-904"><a href="#cb50-904" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> label, words <span class="kw">in</span> clusters.items():</span>
<span id="cb50-905"><a href="#cb50-905" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Cluster </span><span class="sc">{</span>label<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb50-906"><a href="#cb50-906" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> word <span class="kw">in</span> words:</span>
<span id="cb50-907"><a href="#cb50-907" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>word<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb50-908"><a href="#cb50-908" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb50-909"><a href="#cb50-909" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-910"><a href="#cb50-910" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Explain clusters</span></span>
<span id="cb50-911"><a href="#cb50-911" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Cluster explanations based on semantics and ideas:"</span>)</span>
<span id="cb50-912"><a href="#cb50-912" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> label, words <span class="kw">in</span> clusters.items():</span>
<span id="cb50-913"><a href="#cb50-913" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Cluster </span><span class="sc">{</span>label<span class="sc">}</span><span class="ss"> might be related to:"</span>)</span>
<span id="cb50-914"><a href="#cb50-914" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> word <span class="kw">in</span> words:</span>
<span id="cb50-915"><a href="#cb50-915" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>word<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb50-916"><a href="#cb50-916" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb50-917"><a href="#cb50-917" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-918"><a href="#cb50-918" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-919"><a href="#cb50-919" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-920"><a href="#cb50-920" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_48}</span></span>
<span id="cb50-921"><a href="#cb50-921" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch </span>
<span id="cb50-922"><a href="#cb50-922" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-923"><a href="#cb50-923" aria-hidden="true" tabindex="-1"></a>keyword_embeddings <span class="op">=</span> np.array([get_embedding(phrase) <span class="cf">for</span> phrase <span class="kw">in</span> keywords_across_db_nodup])</span>
<span id="cb50-924"><a href="#cb50-924" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-925"><a href="#cb50-925" aria-hidden="true" tabindex="-1"></a>n_clusters <span class="op">=</span> number_of_topics</span>
<span id="cb50-926"><a href="#cb50-926" aria-hidden="true" tabindex="-1"></a>kmeans <span class="op">=</span> KMeans(n_clusters <span class="op">=</span> n_clusters, random_state <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb50-927"><a href="#cb50-927" aria-hidden="true" tabindex="-1"></a>kmeans.fit(keyword_embeddings)</span>
<span id="cb50-928"><a href="#cb50-928" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> kmeans.labels_</span>
<span id="cb50-929"><a href="#cb50-929" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-930"><a href="#cb50-930" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-931"><a href="#cb50-931" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-932"><a href="#cb50-932" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-933"><a href="#cb50-933" aria-hidden="true" tabindex="-1"></a><span class="in">```{python chunk_theme_49}</span></span>
<span id="cb50-934"><a href="#cb50-934" aria-hidden="true" tabindex="-1"></a>print_clusters(n_clusters, keywords_across_db_nodup)</span>
<span id="cb50-935"><a href="#cb50-935" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb50-936"><a href="#cb50-936" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-937"><a href="#cb50-937" aria-hidden="true" tabindex="-1"></a><span class="al">![](/images/keyclusters.png)</span></span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>